'use client';

import { useState, useEffect, useRef } from 'react';
import { useRouter } from 'next/navigation';
import { toast } from 'sonner';
import { apiClient } from '@/lib/api-client';
import { useDashboardStore } from '@/store/dashboard-store';
import {
  detectPlatform,
  detectMediaCapabilities,
  getOptimalRecordingConfig,
  isMediaRecordingSupported,
  isFileSelectionSupported,
  PlatformType,
  MediaCapabilities,
} from '@/utils/multimodal-platform-utils';
import {
  ensureMicrophonePermission,
  showPermissionGuide,
  checkMicrophonePermissionStatus
} from '@/utils/microphone-permissions';
import {
  parseError,
  showError,
  showSuccess,
  showInfo,
  showWarning,
  createError,
  MultimodalErrorType,
  isRetryableError,
} from '@/utils/multimodal-error-handler';
import { 
  MicrophoneIcon, 
  EyeIcon, 
  PhotoIcon,
  StopIcon,
  ArrowPathIcon,
  XMarkIcon
} from '@heroicons/react/24/outline';
import '@/styles/smart-accounting-dialog.css';

interface EnhancedSmartAccountingDialogProps {
  isOpen: boolean;
  onClose: () => void;
  accountBookId?: string;
}

interface MultimodalAIStatus {
  speech: {
    enabled: boolean;
    provider: string;
    model: string;
    supportedFormats: string[];
    maxFileSize: number;
  };
  vision: {
    enabled: boolean;
    provider: string;
    model: string;
    supportedFormats: string[];
    maxFileSize: number;
  };
  general: {
    enabled: boolean;
    dailyLimit: number;
    userLimit: number;
  };
  smartAccounting: {
    speechEnabled: boolean;
    visionEnabled: boolean;
  };
}

export default function EnhancedSmartAccountingDialog({
  isOpen,
  onClose,
  accountBookId,
}: EnhancedSmartAccountingDialogProps) {
  const router = useRouter();
  const { refreshDashboardData } = useDashboardStore();
  
  const [description, setDescription] = useState('');
  const [isProcessing, setIsProcessing] = useState(false);
  const [processingStep, setProcessingStep] = useState('');

  // å¤šæ¨¡æ€åŠŸèƒ½çŠ¶æ€
  const [multimodalStatus, setMultimodalStatus] = useState<MultimodalAIStatus | null>(null);
  const [platform, setPlatform] = useState<PlatformType>(PlatformType.UNKNOWN);
  const [mediaCapabilities, setMediaCapabilities] = useState<MediaCapabilities | null>(null);
  const [isRecording, setIsRecording] = useState(false);
  const [mediaRecorder, setMediaRecorder] = useState<MediaRecorder | null>(null);
  const [audioChunks, setAudioChunks] = useState<Blob[]>([]);
  const [selectedImage, setSelectedImage] = useState<File | null>(null);
  const [imagePreview, setImagePreview] = useState<string | null>(null);
  const [isProcessingMultimodal, setIsProcessingMultimodal] = useState(false);
  const [recordingCancelled, setRecordingCancelled] = useState(false);
  const [touchStartPos, setTouchStartPos] = useState<{ x: number; y: number } | null>(null);
  const fileInputRef = useRef<HTMLInputElement>(null);
  const micButtonRef = useRef<HTMLButtonElement>(null);

  // æ–°å¢çŠ¶æ€ï¼šæ»‘åŠ¨æ‰‹åŠ¿æ£€æµ‹
  const [gestureType, setGestureType] = useState<'none' | 'cancel' | 'fill-text'>('none');
  const [showGestureHint, setShowGestureHint] = useState(false);
  const gestureTypeRef = useRef<'none' | 'cancel' | 'fill-text'>('none');







  // åˆå§‹åŒ–å¤šæ¨¡æ€çŠ¶æ€
  const loadMultimodalStatus = async () => {
    try {
      const response = await apiClient.get('/ai/multimodal/status');
      if (response?.success && response?.data) {
        setMultimodalStatus(response.data);
      }
    } catch (error) {
      console.error('è·å–å¤šæ¨¡æ€AIçŠ¶æ€å¤±è´¥:', error);
    }
  };

  // å¼€å§‹å½•éŸ³ï¼ˆé•¿æŒ‰å¼€å§‹ï¼‰
  const startRecording = async () => {
    if (!accountBookId) {
      toast.error('è¯·å…ˆé€‰æ‹©è´¦æœ¬');
      return;
    }

    try {
      if (!isMediaRecordingSupported()) {
        showError(createError(
          MultimodalErrorType.PLATFORM_NOT_SUPPORTED,
          'å½“å‰è®¾å¤‡ä¸æ”¯æŒå½•éŸ³åŠŸèƒ½'
        ));
        return;
      }

      // é¦–å…ˆè¯·æ±‚éº¦å…‹é£æƒé™
      console.log('ğŸ¤ å¼€å§‹è¯·æ±‚éº¦å…‹é£æƒé™...');
      const permissionResult = await ensureMicrophonePermission();
      
      if (!permissionResult.granted) {
        console.error('ğŸ¤ éº¦å…‹é£æƒé™è¢«æ‹’ç»:', permissionResult.error);
        
        // æ£€æŸ¥å½“å‰ç¯å¢ƒ
        const isAndroid = typeof window !== 'undefined' && 
                         (window as any).Capacitor?.getPlatform?.() === 'android';
        
        if (permissionResult.canRetry) {
          showError(createError(
            MultimodalErrorType.PERMISSION_DENIED,
            permissionResult.error || 'éº¦å…‹é£æƒé™è¢«æ‹’ç»'
          ));
          
          // å¦‚æœæ˜¯Androidç¯å¢ƒï¼Œæ˜¾ç¤ºè¯¦ç»†çš„æƒé™æŒ‡å¯¼
          if (isAndroid) {
            setTimeout(() => {
              showPermissionGuide(true);
            }, 2000);
          }
        } else {
          showError(createError(
            MultimodalErrorType.PLATFORM_NOT_SUPPORTED,
            permissionResult.error || 'éº¦å…‹é£åŠŸèƒ½ä¸å¯ç”¨'
          ));
        }
        return;
      }

      console.log('ğŸ¤ éº¦å…‹é£æƒé™è·å–æˆåŠŸï¼Œå¼€å§‹å½•éŸ³...');
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const chunks: Blob[] = [];
      const recorder = new MediaRecorder(stream);

      // æ·»åŠ è¶…æ—¶ä¿æŠ¤
      const recordingTimeout = setTimeout(() => {
        console.log('ğŸ¤ [StartRecording] å½•éŸ³è¶…æ—¶ï¼Œè‡ªåŠ¨åœæ­¢');
        if (recorder.state === 'recording') {
          recorder.stop();
        }
      }, 60000); // 60ç§’è¶…æ—¶

      recorder.ondataavailable = (event) => {
        console.log('ğŸ¤ [MediaRecorder] æ•°æ®å¯ç”¨:', event.data.size);
        if (event.data.size > 0) {
          chunks.push(event.data);
        }
      };

      recorder.onstop = () => {
        console.log('ğŸ¤ [MediaRecorder] å½•éŸ³åœæ­¢äº‹ä»¶è§¦å‘');
        clearTimeout(recordingTimeout);
        
        // åœæ­¢æ‰€æœ‰éŸ³é¢‘è½¨é“
        stream.getTracks().forEach(track => {
          console.log('ğŸ¤ [MediaRecorder] åœæ­¢éŸ³é¢‘è½¨é“:', track.label);
          track.stop();
        });

        // ç¡®ä¿UIçŠ¶æ€æ›´æ–°
        setIsRecording(false);
        setMediaRecorder(null);

        // åªæœ‰åœ¨æ²¡æœ‰å–æ¶ˆçš„æƒ…å†µä¸‹æ‰è¿›è¡Œè¯­éŸ³è¯†åˆ«
        if (!recordingCancelled && chunks.length > 0) {
          console.log('ğŸ¤ [MediaRecorder] å¼€å§‹è¯­éŸ³è¯†åˆ«ï¼ŒéŸ³é¢‘å—æ•°:', chunks.length);
          const audioBlob = new Blob(chunks, { type: 'audio/webm' });
          handleSpeechRecognition(audioBlob, gestureTypeRef.current);
        } else {
          console.log('ğŸ¤ [MediaRecorder] è·³è¿‡è¯­éŸ³è¯†åˆ«ï¼Œå–æ¶ˆçŠ¶æ€:', recordingCancelled, 'éŸ³é¢‘å—æ•°:', chunks.length);
        }
      };

      recorder.onerror = (event) => {
        console.error('ğŸ¤ [MediaRecorder] å½•éŸ³é”™è¯¯:', event);
        clearTimeout(recordingTimeout);
        
        // æ¸…ç†èµ„æº
        stream.getTracks().forEach(track => track.stop());
        setIsRecording(false);
        setMediaRecorder(null);
        
        showError(createError(
          MultimodalErrorType.RECORDING_FAILED,
          'å½•éŸ³è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯'
        ));
      };

      recorder.start();
      setMediaRecorder(recorder);
      setAudioChunks(chunks);
      setIsRecording(true);
      setRecordingCancelled(false);
      
      // é‡ç½®æ‰‹åŠ¿çŠ¶æ€
      setGestureType('none');
      gestureTypeRef.current = 'none';
      setShowGestureHint(false);

      console.log('ğŸ¤ [StartRecording] å½•éŸ³å·²å¯åŠ¨ï¼ŒçŠ¶æ€:', recorder.state);
      showInfo('æ­£åœ¨å½•éŸ³ï¼Œæ¾å¼€åœæ­¢ï¼Œå‘ä¸Šæ»‘åŠ¨å–æ¶ˆ');
    } catch (error) {
      console.error('å¯åŠ¨å½•éŸ³å¤±è´¥:', error);
      
      // ç¡®ä¿çŠ¶æ€é‡ç½®
      setIsRecording(false);
      setMediaRecorder(null);
      
      showError(error);
    }
  };

  // åœæ­¢å½•éŸ³ï¼ˆæ¾å¼€æ‰‹æŒ‡ï¼‰
  const stopRecording = (gestureType: 'none' | 'cancel' | 'fill-text' = 'none') => {
    console.log('ğŸ¤ [StopRecording] è°ƒç”¨åœæ­¢å½•éŸ³ï¼Œå½“å‰çŠ¶æ€:', {
      mediaRecorder: mediaRecorder?.state,
      isRecording,
      recordingCancelled,
      gestureType
    });
    
    if (mediaRecorder && mediaRecorder.state === 'recording') {
      console.log('ğŸ¤ [StopRecording] æ­£åœ¨åœæ­¢MediaRecorder...');
      mediaRecorder.stop();
    }
    
    // ç«‹å³æ›´æ–°UIçŠ¶æ€
    setIsRecording(false);
    setMediaRecorder(null);
    setTouchStartPos(null);
    
    console.log('ğŸ¤ [StopRecording] å½•éŸ³çŠ¶æ€å·²é‡ç½®');
  };

  // å–æ¶ˆå½•éŸ³
  const cancelRecording = () => {
    console.log('ğŸ¤ [CancelRecording] å–æ¶ˆå½•éŸ³');
    setRecordingCancelled(true);
    
    if (mediaRecorder && mediaRecorder.state === 'recording') {
      console.log('ğŸ¤ [CancelRecording] åœæ­¢MediaRecorder...');
      mediaRecorder.stop();
    }
    
    // ç«‹å³æ›´æ–°UIçŠ¶æ€
    setIsRecording(false);
    setMediaRecorder(null);
    setTouchStartPos(null);
    showInfo('å½•éŸ³å·²å–æ¶ˆ');
    
    console.log('ğŸ¤ [CancelRecording] å½•éŸ³å·²å–æ¶ˆï¼ŒçŠ¶æ€å·²é‡ç½®');
  };

  // å¤„ç†è§¦æ‘¸å¼€å§‹
  const handleTouchStart = (e: React.TouchEvent) => {
    e.preventDefault();
    console.log('ğŸ¤ [TouchStart] è§¦æ‘¸å¼€å§‹');
    const touch = e.touches[0];
    setTouchStartPos({ x: touch.clientX, y: touch.clientY });
    startRecording();
  };

  // å¤„ç†è§¦æ‘¸ç§»åŠ¨ï¼ˆæ£€æµ‹æ˜¯å¦è¦å–æ¶ˆï¼‰
  const handleTouchMove = (e: React.TouchEvent) => {
    if (!touchStartPos || !isRecording) return;

    const touch = e.touches[0];
    const deltaY = touchStartPos.y - touch.clientY;
    const deltaX = Math.abs(touch.clientX - touchStartPos.x);

    console.log('ğŸ¤ [TouchMove] è§¦æ‘¸ç§»åŠ¨:', { deltaY, deltaX });

    // æ£€æµ‹æ‰‹åŠ¿ç±»å‹
    if (Math.abs(deltaY) > 30 && deltaX < 50) { // å‚ç›´æ»‘åŠ¨ï¼Œæ°´å¹³åç§»ä¸è¶…è¿‡50px
      if (deltaY > 50) {
        // å‘ä¸Šæ»‘åŠ¨ - å–æ¶ˆå½•éŸ³
        if (gestureTypeRef.current !== 'cancel') {
          setGestureType('cancel');
          gestureTypeRef.current = 'cancel';
          setShowGestureHint(true);
          console.log('ğŸ¤ [TouchMove] æ£€æµ‹åˆ°å–æ¶ˆæ‰‹åŠ¿');
        }
      } else if (deltaY < -50) {
        // å‘ä¸‹æ»‘åŠ¨ - å¡«å…¥æ–‡æœ¬æ¡†
        if (gestureTypeRef.current !== 'fill-text') {
          setGestureType('fill-text');
          gestureTypeRef.current = 'fill-text';
          setShowGestureHint(true);
          console.log('ğŸ¤ [TouchMove] æ£€æµ‹åˆ°å¡«å…¥æ–‡æœ¬æ‰‹åŠ¿');
        }
      }
    } else if (Math.abs(deltaY) < 30) {
      // æ²¡æœ‰æ˜æ˜¾çš„å‚ç›´æ»‘åŠ¨
      if (gestureTypeRef.current !== 'none') {
        setGestureType('none');
        gestureTypeRef.current = 'none';
        setShowGestureHint(false);
      }
    }
  };

  // å¤„ç†è§¦æ‘¸ç»“æŸ
  const handleTouchEnd = (e: React.TouchEvent) => {
    e.preventDefault();
    console.log('ğŸ¤ [TouchEnd] è§¦æ‘¸ç»“æŸï¼Œå½“å‰çŠ¶æ€:', { isRecording, recordingCancelled, gestureType });
    
    if (isRecording && !recordingCancelled) {
      if (gestureType === 'cancel') {
        // ä¸Šæ»‘å–æ¶ˆå½•éŸ³
        console.log('ğŸ¤ [TouchEnd] æ‰§è¡Œå–æ¶ˆå½•éŸ³');
        cancelRecording();
      } else {
        // æ¾å¼€åœæ­¢å½•éŸ³ï¼Œæ ¹æ®æ‰‹åŠ¿ç±»å‹å†³å®šåç»­æ“ä½œ
        console.log('ğŸ¤ [TouchEnd] æ­£å¸¸ç»“æŸå½•éŸ³ï¼Œæ‰‹åŠ¿ç±»å‹:', gestureType);
        stopRecording(gestureType);
      }
    } else {
      console.log('ğŸ¤ [TouchEnd] å½•éŸ³å·²å–æ¶ˆæˆ–æœªåœ¨å½•éŸ³çŠ¶æ€');
    }

    // é‡ç½®æ‰‹åŠ¿çŠ¶æ€
    setGestureType('none');
    gestureTypeRef.current = 'none';
    setShowGestureHint(false);
  };

  // å¤„ç†é¼ æ ‡äº‹ä»¶ï¼ˆæ¡Œé¢ç«¯ï¼‰
  const handleMouseDown = (e: React.MouseEvent) => {
    e.preventDefault();
    console.log('ğŸ¤ [MouseDown] é¼ æ ‡æŒ‰ä¸‹');
    setTouchStartPos({ x: e.clientX, y: e.clientY });
    startRecording();
  };

  const handleMouseMove = (e: React.MouseEvent) => {
    if (!touchStartPos || !isRecording) return;

    const deltaY = touchStartPos.y - e.clientY;
    const deltaX = Math.abs(e.clientX - touchStartPos.x);

    console.log('ğŸ¤ [MouseMove] é¼ æ ‡ç§»åŠ¨:', { deltaY, deltaX });

    // æ£€æµ‹æ‰‹åŠ¿ç±»å‹ï¼ˆä¸è§¦æ‘¸ç›¸åŒï¼‰
    if (Math.abs(deltaY) > 30 && deltaX < 50) { // å‚ç›´ç§»åŠ¨ï¼Œæ°´å¹³åç§»ä¸è¶…è¿‡50px
      if (deltaY > 50) {
        // å‘ä¸Šç§»åŠ¨ - å–æ¶ˆå½•éŸ³
        if (gestureTypeRef.current !== 'cancel') {
          setGestureType('cancel');
          gestureTypeRef.current = 'cancel';
          setShowGestureHint(true);
          console.log('ğŸ¤ [MouseMove] æ£€æµ‹åˆ°å–æ¶ˆæ‰‹åŠ¿');
        }
      } else if (deltaY < -50) {
        // å‘ä¸‹ç§»åŠ¨ - å¡«å…¥æ–‡æœ¬æ¡†
        if (gestureTypeRef.current !== 'fill-text') {
          setGestureType('fill-text');
          gestureTypeRef.current = 'fill-text';
          setShowGestureHint(true);
          console.log('ğŸ¤ [MouseMove] æ£€æµ‹åˆ°å¡«å…¥æ–‡æœ¬æ‰‹åŠ¿');
        }
      }
    } else if (Math.abs(deltaY) < 30) {
      // æ²¡æœ‰æ˜æ˜¾çš„å‚ç›´ç§»åŠ¨
      if (gestureTypeRef.current !== 'none') {
        setGestureType('none');
        gestureTypeRef.current = 'none';
        setShowGestureHint(false);
      }
    }
  };

  const handleMouseUp = (e: React.MouseEvent) => {
    e.preventDefault();
    console.log('ğŸ¤ [MouseUp] é¼ æ ‡é‡Šæ”¾ï¼Œå½“å‰çŠ¶æ€:', { isRecording, recordingCancelled, gestureType });
    
    if (isRecording && !recordingCancelled) {
      if (gestureType === 'cancel') {
        // ä¸Šç§»å–æ¶ˆå½•éŸ³
        console.log('ğŸ¤ [MouseUp] æ‰§è¡Œå–æ¶ˆå½•éŸ³');
        cancelRecording();
      } else {
        // æ¾å¼€åœæ­¢å½•éŸ³ï¼Œæ ¹æ®æ‰‹åŠ¿ç±»å‹å†³å®šåç»­æ“ä½œ
        console.log('ğŸ¤ [MouseUp] æ­£å¸¸ç»“æŸå½•éŸ³ï¼Œæ‰‹åŠ¿ç±»å‹:', gestureType);
        stopRecording(gestureType);
      }
    } else {
      console.log('ğŸ¤ [MouseUp] å½•éŸ³å·²å–æ¶ˆæˆ–æœªåœ¨å½•éŸ³çŠ¶æ€');
    }

    // é‡ç½®æ‰‹åŠ¿çŠ¶æ€
    setGestureType('none');
    gestureTypeRef.current = 'none';
    setShowGestureHint(false);
  };

  // å¤„ç†è¯­éŸ³è¯†åˆ«
  const handleSpeechRecognition = async (audioBlob: Blob, gestureType: 'none' | 'cancel' | 'fill-text') => {
    if (!accountBookId) {
      toast.error('è¯·å…ˆé€‰æ‹©è´¦æœ¬');
      return;
    }

    setIsProcessingMultimodal(true);

    try {
      const formData = new FormData();
      formData.append('audio', audioBlob, 'recording.webm');
      formData.append('accountBookId', accountBookId);

      const response = await apiClient.post('/ai/smart-accounting/speech', formData, {
        headers: {
          'Content-Type': 'multipart/form-data',
        },
        timeout: 60000,
      });

      if (response && response.data && response.data.text) {
        const recognizedText = response.data.text;
        setDescription(recognizedText);
        showSuccess('è¯­éŸ³è¯†åˆ«æˆåŠŸ');

        // æ ¹æ®æ‰‹åŠ¿ç±»å‹æ‰§è¡Œä¸åŒæ“ä½œ
        if (gestureType === 'cancel') {
          // å–æ¶ˆå½•éŸ³çš„æƒ…å†µä¸‹ï¼Œä¸åº”è¯¥åˆ°è¿™é‡Œï¼Œè¿™é‡Œåªæ˜¯ä¿æŠ¤æ€§ä»£ç 
          console.log('ğŸ¤ [SpeechRecognition] å½•éŸ³å·²å–æ¶ˆï¼Œè·³è¿‡å¤„ç†');
          return;
        } else if (gestureType === 'fill-text') {
          // å¡«å…¥æ–‡æœ¬æ¡†ï¼Œä¸è‡ªåŠ¨è°ƒç”¨è®°è´¦
          setDescription(recognizedText);
          showSuccess('è¯­éŸ³å·²è½¬æ¢ä¸ºæ–‡å­—');
        } else {
          // æ­£å¸¸ç»“æŸå½•éŸ³ï¼Œç›´æ¥è°ƒç”¨è®°è´¦
          setDescription(recognizedText);
          await handleSmartAccountingWithText(recognizedText);
        }
      } else {
        showError(createError(
          MultimodalErrorType.RECOGNITION_FAILED,
          'è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•'
        ));
      }
    } catch (error: any) {
      console.error('è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
      showError(error);
    } finally {
      setIsProcessingMultimodal(false);
    }
  };

  // å¤„ç†å›¾ç‰‡è®°è´¦
  const handleImageRecording = () => {
    if (!accountBookId) {
      toast.error('è¯·å…ˆé€‰æ‹©è´¦æœ¬');
      return;
    }

    if (!isFileSelectionSupported()) {
      showError(createError(
        MultimodalErrorType.PLATFORM_NOT_SUPPORTED,
        'å½“å‰è®¾å¤‡ä¸æ”¯æŒæ–‡ä»¶é€‰æ‹©åŠŸèƒ½'
      ));
      return;
    }

    fileInputRef.current?.click();
  };

  // å¤„ç†å›¾ç‰‡é€‰æ‹©
  const handleImageSelect = (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (!file) return;

    // éªŒè¯æ–‡ä»¶æ ¼å¼
    if (!file.type.startsWith('image/')) {
      showError(createError(
        MultimodalErrorType.INVALID_FILE_FORMAT,
        'è¯·é€‰æ‹©å›¾ç‰‡æ–‡ä»¶'
      ));
      return;
    }

    handleImageRecognition(file);
  };

  // å¤„ç†å›¾ç‰‡è¯†åˆ«
  const handleImageRecognition = async (imageFile: File) => {
    if (!accountBookId) {
      toast.error('è¯·å…ˆé€‰æ‹©è´¦æœ¬');
      return;
    }

    setIsProcessingMultimodal(true);

    try {
      const formData = new FormData();
      formData.append('image', imageFile);
      formData.append('accountBookId', accountBookId);

      const response = await apiClient.post('/ai/smart-accounting/vision', formData, {
        headers: {
          'Content-Type': 'multipart/form-data',
        },
        timeout: 60000,
      });

      if (response && response.data && response.data.text) {
        const recognizedText = response.data.text;
        setDescription(recognizedText);
        showSuccess('å›¾ç‰‡è¯†åˆ«æˆåŠŸ');

        // è‡ªåŠ¨è°ƒç”¨æ™ºèƒ½è®°è´¦
        await handleSmartAccountingWithText(recognizedText);
      } else {
        showError(createError(
          MultimodalErrorType.RECOGNITION_FAILED,
          'å›¾ç‰‡è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•'
        ));
      }
    } catch (error: any) {
      console.error('å›¾ç‰‡è¯†åˆ«å¤±è´¥:', error);
      showError(error);
    } finally {
      setIsProcessingMultimodal(false);
      // æ¸…é™¤æ–‡ä»¶è¾“å…¥
      if (fileInputRef.current) {
        fileInputRef.current.value = '';
      }
    }
  };

  // ä½¿ç”¨è¯†åˆ«çš„æ–‡æœ¬è¿›è¡Œæ™ºèƒ½è®°è´¦
  const handleSmartAccountingWithText = async (text: string) => {
    try {
      setIsProcessing(true);
      setProcessingStep('æ­£åœ¨åˆ†æè®°è´¦ä¿¡æ¯...');

      const response = await apiClient.post(
        `/ai/account/${accountBookId}/smart-accounting`,
        { description: text },
        { timeout: 60000 }
      );

      if (response) {
        // å°†ç»“æœå­˜å‚¨åˆ°sessionStorageï¼Œä¾›æ·»åŠ äº¤æ˜“é¡µé¢ä½¿ç”¨
        sessionStorage.setItem('smartAccountingResult', JSON.stringify(response));
        showSuccess('æ™ºèƒ½è¯†åˆ«æˆåŠŸ');
        onClose();
        router.push('/transactions/new');
      } else {
        showError(createError(
          MultimodalErrorType.PROCESSING_ERROR,
          'æ™ºèƒ½è¯†åˆ«å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨å¡«å†™'
        ));
      }
    } catch (error: any) {
      console.error('æ™ºèƒ½è®°è´¦å¤±è´¥:', error);

      if (error.response?.data?.info && error.response.data.info.includes('è®°è´¦æ— å…³')) {
        showInfo('æ‚¨çš„æè¿°ä¼¼ä¹ä¸è®°è´¦æ— å…³ï¼Œè¯·å°è¯•æè¿°å…·ä½“çš„æ¶ˆè´¹æˆ–æ”¶å…¥æƒ…å†µ');
      } else {
        showError(error);
      }
    } finally {
      setIsProcessing(false);
      setProcessingStep('');
    }
  };

  // æ™ºèƒ½è®°è´¦
  const handleSmartAccounting = async () => {
    if (!description.trim()) {
      toast.error('è¯·è¾“å…¥æè¿°');
      return;
    }

    await handleSmartAccountingWithText(description.trim());
  };

  // å¤„ç†ç›´æ¥æ·»åŠ è®°è´¦
  const handleDirectAdd = async () => {
    if (!description.trim()) {
      toast.error('è¯·è¾“å…¥æè¿°');
      return;
    }

    if (!accountBookId) {
      toast.error('è¯·å…ˆé€‰æ‹©è´¦æœ¬');
      return;
    }

    try {
      setIsProcessing(true);
      setProcessingStep('æ­£åœ¨åˆ›å»ºäº¤æ˜“è®°å½•...');

      // è°ƒç”¨ç›´æ¥æ·»åŠ è®°è´¦API
      const response = await apiClient.post(
        `/ai/account/${accountBookId}/smart-accounting/direct`,
        { description },
        { timeout: 60000 }
      );

      if (response && response.id) {
        toast.success('è®°è´¦æˆåŠŸ');

        // åˆ·æ–°ä»ªè¡¨ç›˜æ•°æ®
        if (accountBookId) {
          try {
            await refreshDashboardData(accountBookId);
          } catch (refreshError) {
            console.error('åˆ·æ–°ä»ªè¡¨ç›˜æ•°æ®å¤±è´¥:', refreshError);
          }
        }

        onClose();
        setDescription('');
      } else {
        toast.error('è®°è´¦å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨å¡«å†™');
      }
    } catch (error: any) {
      console.error('ç›´æ¥æ·»åŠ è®°è´¦å¤±è´¥:', error);

      let errorMessage = 'è®°è´¦å¤±è´¥ï¼Œè¯·é‡è¯•';

      if (error.response) {
        const errorData = error.response.data;

        if (error.response.status === 429 && errorData?.type === 'TOKEN_LIMIT_EXCEEDED') {
          errorMessage = `${errorData.error || 'Tokenä½¿ç”¨é‡å·²è¾¾é™é¢ï¼Œè¯·ç¨åå†è¯•'}`;
        } else if (errorData?.info && errorData.info.includes('è®°è´¦æ— å…³')) {
          errorMessage = 'æ‚¨çš„æè¿°ä¼¼ä¹ä¸è®°è´¦æ— å…³ï¼Œè¯·å°è¯•æè¿°å…·ä½“çš„æ¶ˆè´¹æˆ–æ”¶å…¥æƒ…å†µ';
        } else {
          errorMessage = `è®°è´¦å¤±è´¥: ${errorData?.error || errorData?.message || 'æœåŠ¡å™¨é”™è¯¯'}`;
        }
      } else if (error.request) {
        errorMessage = 'ç½‘ç»œè¿æ¥å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥ç½‘ç»œåé‡è¯•';
      }

      toast.error(errorMessage);
    } finally {
      setIsProcessing(false);
      setProcessingStep('');
    }
  };

  // æ‰‹åŠ¨è®°è´¦
  const handleManualAccounting = () => {
    onClose();
    router.push('/transactions/new');
  };

  // æ¸…é™¤å›¾ç‰‡é€‰æ‹©
  const clearImageSelection = () => {
    setSelectedImage(null);
    setImagePreview(null);
    if (fileInputRef.current) {
      fileInputRef.current.value = '';
    }
  };

  useEffect(() => {
    if (isOpen) {
      // åˆå§‹åŒ–å¤šæ¨¡æ€çŠ¶æ€
      loadMultimodalStatus();
    }
  }, [isOpen]);

  if (!isOpen) return null;

  // å¤„ç†ç‚¹å‡»ç©ºç™½å¤„å…³é—­å¼¹çª—
  const handleOverlayClick = (e: React.MouseEvent) => {
    if (e.target === e.currentTarget) {
      onClose();
    }
  };

  return (
    <div className="smart-accounting-dialog-overlay" onClick={handleOverlayClick}>
      <div className="smart-accounting-dialog" style={{ position: 'relative' }}>
        <div className="smart-accounting-dialog-header">
          <h3 className="smart-accounting-dialog-title">æ™ºèƒ½è®°è´¦</h3>
          <button className="smart-accounting-dialog-close" onClick={onClose}>
            <XMarkIcon className="w-5 h-5" />
          </button>
        </div>

        {isProcessing ? (
          <div className="smart-accounting-processing">
            <div className="smart-accounting-loading">
              <div className="spinner"></div>
            </div>
            <p className="smart-accounting-processing-text">{processingStep || 'æ­£åœ¨å¤„ç†...'}</p>
          </div>
        ) : (
          <>
            <div className="smart-accounting-dialog-content">
              <p className="smart-accounting-dialog-subtitle">è¾“å…¥ä¸€å¥è¯ï¼Œè‡ªåŠ¨è¯†åˆ«è®°è´¦ä¿¡æ¯</p>

              {/* æ–‡æœ¬è¾“å…¥ */}
              <div className="smart-accounting-input-wrapper">
                <textarea
                  className="smart-accounting-textarea"
                  placeholder="ä¾‹å¦‚ï¼šæ˜¨å¤©åœ¨æ²ƒå°”ç›ä¹°äº†æ—¥ç”¨å“ï¼ŒèŠ±äº†128.5å…ƒ"
                  value={description}
                  onChange={(e) => setDescription(e.target.value)}
                  rows={3}
                  autoFocus
                />
              </div>

              {/* å½•éŸ³çŠ¶æ€æç¤º */}
              {isRecording && (
                <div style={{
                  position: 'absolute',
                  top: '50%',
                  left: '50%',
                  transform: 'translate(-50%, -50%)',
                  backgroundColor: 'rgba(0, 0, 0, 0.8)',
                  color: 'white',
                  padding: '20px',
                  borderRadius: '12px',
                  textAlign: 'center',
                  zIndex: 1000,
                  minWidth: '200px'
                }}>
                  <div style={{
                    width: '40px',
                    height: '40px',
                    borderRadius: '50%',
                    backgroundColor: 'var(--error-color, #ef4444)',
                    display: 'flex',
                    alignItems: 'center',
                    justifyContent: 'center',
                    margin: '0 auto 12px',
                    animation: 'recordingPulse 1.5s ease-in-out infinite'
                  }}>
                    <i className="fas fa-microphone" style={{ fontSize: '16px', color: 'white' }}></i>
                  </div>
                  <p style={{ margin: '0 0 8px', fontSize: '14px', fontWeight: 'bold' }}>
                    æ­£åœ¨å½•éŸ³...
                  </p>
                  {showGestureHint && (
                    <p style={{ margin: 0, fontSize: '12px', opacity: 0.9 }}>
                      {gestureType === 'cancel' ? 'æ¾å¼€å–æ¶ˆå½•éŸ³' : 
                       gestureType === 'fill-text' ? 'æ¾å¼€å¡«å…¥æ–‡æœ¬æ¡†' : 
                       'æ¾å¼€è½¬æ¢æ–‡å­—å¹¶è®°è´¦'}
                    </p>
                  )}
                  {!showGestureHint && (
                    <p style={{ margin: 0, fontSize: '12px', opacity: 0.7 }}>
                      ä¸Šæ»‘å–æ¶ˆ â€¢ ä¸‹æ»‘å¡«å…¥æ–‡æœ¬æ¡† â€¢ æ¾å¼€ç›´æ¥è®°è´¦
                    </p>
                  )}
                </div>
              )}

              <div className="smart-accounting-buttons">
                <button
                  className="smart-accounting-button identify-button"
                  onClick={handleSmartAccounting}
                  disabled={isProcessing || !description.trim()}
                >
                  æ™ºèƒ½è¯†åˆ«
                </button>

                <button
                  className="smart-accounting-button direct-button"
                  onClick={handleDirectAdd}
                  disabled={!description.trim()}
                >
                  ç›´æ¥æ·»åŠ 
                </button>
              </div>

              <div className="smart-accounting-manual-wrapper">
                {/* éšè—çš„æ–‡ä»¶è¾“å…¥ */}
                <input
                  ref={fileInputRef}
                  type="file"
                  accept="image/*"
                  onChange={handleImageSelect}
                  style={{ display: 'none' }}
                />

                {/* åº•éƒ¨æŒ‰é’®ç»„ï¼šç›¸æœº - æ‰‹åŠ¨è®°è´¦ - éº¦å…‹é£ */}
                <div style={{
                  display: 'flex',
                  gap: '12px',
                  alignItems: 'center'
                }}>
                  {/* ç›¸æœºæŒ‰é’® */}
                  <button
                    type="button"
                    onClick={handleImageRecording}
                    disabled={isProcessing || isProcessingMultimodal}
                    style={{
                      width: '48px',
                      height: '48px',
                      borderRadius: '12px',
                      border: 'none',
                      backgroundColor: 'var(--success-color, #22c55e)',
                      color: 'white',
                      fontSize: '18px',
                      cursor: (isProcessing || isProcessingMultimodal) ? 'not-allowed' : 'pointer',
                      opacity: (isProcessing || isProcessingMultimodal) ? 0.6 : 1,
                      transition: 'all 0.2s ease',
                      display: 'flex',
                      alignItems: 'center',
                      justifyContent: 'center',
                      boxShadow: '0 2px 8px rgba(0, 0, 0, 0.1)'
                    }}
                    title="å›¾ç‰‡è®°è´¦"
                  >
                    {isProcessingMultimodal ? (
                      <i className="fas fa-spinner fa-spin"></i>
                    ) : (
                      <i className="fas fa-camera"></i>
                    )}
                  </button>

                  {/* æ‰‹åŠ¨è®°è´¦æŒ‰é’® */}
                  <button
                    className="smart-accounting-manual-button"
                    onClick={handleManualAccounting}
                    style={{ flex: 1 }}
                  >
                    æ‰‹åŠ¨è®°è´¦
                  </button>

                  {/* éº¦å…‹é£æŒ‰é’® */}
                  <button
                    ref={micButtonRef}
                    type="button"
                    disabled={isProcessing || isProcessingMultimodal}
                    onTouchStart={handleTouchStart}
                    onTouchMove={handleTouchMove}
                    onTouchEnd={handleTouchEnd}
                    onMouseDown={handleMouseDown}
                    onMouseMove={handleMouseMove}
                    onMouseUp={handleMouseUp}
                    onMouseLeave={handleMouseUp} // é¼ æ ‡ç¦»å¼€æŒ‰é’®åŒºåŸŸæ—¶ä¹Ÿåœæ­¢å½•éŸ³
                    style={{
                      width: '48px',
                      height: '48px',
                      borderRadius: '12px',
                      border: 'none',
                      backgroundColor: isRecording ? 'var(--error-color, #ef4444)' : 'var(--warning-color, #f59e0b)',
                      color: 'white',
                      fontSize: '18px',
                      cursor: (isProcessing || isProcessingMultimodal) ? 'not-allowed' : 'pointer',
                      opacity: (isProcessing || isProcessingMultimodal) ? 0.6 : 1,
                      transition: 'all 0.2s ease',
                      display: 'flex',
                      alignItems: 'center',
                      justifyContent: 'center',
                      boxShadow: isRecording ? '0 4px 16px rgba(239, 68, 68, 0.4)' : '0 2px 8px rgba(0, 0, 0, 0.1)',
                      transform: isRecording ? 'scale(1.1)' : 'scale(1)',
                      userSelect: 'none',
                      WebkitUserSelect: 'none',
                      WebkitTouchCallout: 'none'
                    }}
                    title={isRecording ? 'æ¾å¼€åœæ­¢å½•éŸ³ï¼Œå‘ä¸Šæ»‘åŠ¨å–æ¶ˆ' : 'é•¿æŒ‰å¼€å§‹è¯­éŸ³è®°è´¦'}
                  >
                    {isProcessingMultimodal ? (
                      <i className="fas fa-spinner fa-spin"></i>
                    ) : isRecording ? (
                      <i className="fas fa-stop"></i>
                    ) : (
                      <i className="fas fa-microphone"></i>
                    )}
                  </button>
                </div>
              </div>
            </div>
          </>
        )}
      </div>
    </div>
  );
}
