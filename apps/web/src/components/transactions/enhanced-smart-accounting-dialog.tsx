'use client';

import { useState, useEffect, useRef } from 'react';
import { useRouter } from 'next/navigation';
import { toast } from 'sonner';
import { apiClient } from '@/lib/api-client';
import { useDashboardStore } from '@/store/dashboard-store';
import {
  detectPlatform,
  detectMediaCapabilities,
  getOptimalRecordingConfig,
  isMediaRecordingSupported,
  isFileSelectionSupported,
  PlatformType,
  MediaCapabilities,
} from '@/utils/multimodal-platform-utils';
import {
  ensureMicrophonePermission,
  showPermissionGuide,
  checkMicrophonePermissionStatus
} from '@/utils/microphone-permissions';
import { 
  parseError,
  showError,
  showSuccess,
  showInfo,
  showWarning,
  createError,
  MultimodalErrorType,
  isRetryableError,
} from '@/utils/multimodal-error-handler';
import { SmartAccountingProgressManager } from '@/components/transactions/smart-accounting-dialog';
import { 
  processAudioForSpeechRecognition,
  getBestAudioFormat,
  detectAudioFormat,
  needsConversion,
  convertAudioToWav
} from '@/lib/audio-conversion';
import { 
  MicrophoneIcon, 
  EyeIcon, 
  PhotoIcon,
  StopIcon,
  ArrowPathIcon,
  XMarkIcon
} from '@heroicons/react/24/outline';
import '@/styles/smart-accounting-dialog.css';

interface EnhancedSmartAccountingDialogProps {
  isOpen: boolean;
  onClose: () => void;
  accountBookId?: string;
}

interface MultimodalAIStatus {
  speech: {
    enabled: boolean;
    provider: string;
    model: string;
    supportedFormats: string[];
    maxFileSize: number;
  };
  vision: {
    enabled: boolean;
    provider: string;
    model: string;
    supportedFormats: string[];
    maxFileSize: number;
  };
  general: {
    enabled: boolean;
    dailyLimit: number;
    userLimit: number;
  };
  smartAccounting: {
    speechEnabled: boolean;
    visionEnabled: boolean;
  };
}

export default function EnhancedSmartAccountingDialog({
  isOpen,
  onClose,
  accountBookId,
}: EnhancedSmartAccountingDialogProps) {
  const router = useRouter();
  const { refreshDashboardData } = useDashboardStore();
  
  const [description, setDescription] = useState('');
  const [isProcessing, setIsProcessing] = useState(false);
  const [processingStep, setProcessingStep] = useState('');

  // å¤šæ¨¡æ€åŠŸèƒ½çŠ¶æ€
  const [multimodalStatus, setMultimodalStatus] = useState<MultimodalAIStatus | null>(null);
  const [platform, setPlatform] = useState<PlatformType>(PlatformType.UNKNOWN);
  const [mediaCapabilities, setMediaCapabilities] = useState<MediaCapabilities | null>(null);
  const [isRecording, setIsRecording] = useState(false);
  const [mediaRecorder, setMediaRecorder] = useState<MediaRecorder | null>(null);
  const [audioChunks, setAudioChunks] = useState<Blob[]>([]);
  const [selectedImage, setSelectedImage] = useState<File | null>(null);
  const [imagePreview, setImagePreview] = useState<string | null>(null);
  const [isProcessingMultimodal, setIsProcessingMultimodal] = useState(false);
  const [recordingCancelled, setRecordingCancelled] = useState(false);
  const [touchStartPos, setTouchStartPos] = useState<{ x: number; y: number } | null>(null);
  const fileInputRef = useRef<HTMLInputElement>(null);
  const micButtonRef = useRef<HTMLButtonElement>(null);
  const [isButtonTouched, setIsButtonTouched] = useState(false);
  const [audioLevel, setAudioLevel] = useState(0);
  const audioAnalyserRef = useRef<AnalyserNode | null>(null);
  const audioDataRef = useRef<Uint8Array | null>(null);
  const animationFrameRef = useRef<number | null>(null);
  const recordingCancelledRef = useRef(false);
  const audioChunksRef = useRef<Blob[]>([]);
  const [animationTime, setAnimationTime] = useState(0);
  const [isAnalyzing, setIsAnalyzing] = useState(false); // æ–°å¢ï¼šç‹¬ç«‹çš„åˆ†æçŠ¶æ€
  const isAnalyzingRef = useRef(false); // æ–°å¢ï¼šç”¨äºç«‹å³æ£€æŸ¥çš„ref

  // æ›´æ–°åŠ¨ç”»æ—¶é—´ç”¨äºå£°æ³¢æ•ˆæœ
  useEffect(() => {
    let animationFrame: number;
    
    if (isAnalyzing) { // æ”¹ä¸ºä½¿ç”¨isAnalyzingçŠ¶æ€
      const updateAnimation = () => {
        setAnimationTime(Date.now());
        animationFrame = requestAnimationFrame(updateAnimation);
      };
      animationFrame = requestAnimationFrame(updateAnimation);
    }
    
    return () => {
      if (animationFrame) {
        cancelAnimationFrame(animationFrame);
      }
    };
  }, [isAnalyzing]); // ä¾èµ–æ”¹ä¸ºisAnalyzing

  // éŸ³é¢‘åˆ†æå™¨è®¾ç½®
  const setupAudioAnalyser = (stream: MediaStream) => {
    try {
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      const analyser = audioContext.createAnalyser();
      const source = audioContext.createMediaStreamSource(stream);
      
      // ç®€åŒ–è®¾ç½®ï¼Œç¡®ä¿å…¼å®¹æ€§
      analyser.fftSize = 256;
      analyser.smoothingTimeConstant = 0.1;
      analyser.minDecibels = -100;
      analyser.maxDecibels = 0;
      
      source.connect(analyser);
      
      audioAnalyserRef.current = analyser;
      audioDataRef.current = new Uint8Array(analyser.frequencyBinCount);
      
      // ä½¿ç”¨refç«‹å³è®¾ç½®çŠ¶æ€ï¼Œç„¶åæ›´æ–°ReactçŠ¶æ€
      isAnalyzingRef.current = true;
      setIsAnalyzing(true);
      
      // ç«‹å³å¼€å§‹åˆ†æéŸ³é¢‘
      analyzeAudio();
      
    } catch (error) {
      console.error('è®¾ç½®éŸ³é¢‘åˆ†æå™¨å¤±è´¥:', error);
    }
  };

  // åˆ†æéŸ³é¢‘æ•°æ®
  const analyzeAudio = () => {
    if (!audioAnalyserRef.current || !audioDataRef.current || !isAnalyzingRef.current) {
      return;
    }
    
    audioAnalyserRef.current.getByteFrequencyData(audioDataRef.current);
    
    // ä¼˜åŒ–çš„éŸ³é¢‘å¼ºåº¦è®¡ç®— - æé«˜æ•æ„Ÿåº¦å’ŒåŠ¨æ€èŒƒå›´
    let sum = 0;
    let max = 0;
    let count = 0;
    
    // è®¡ç®—æ‰€æœ‰é¢‘ç‡æ®µçš„å¹³å‡å€¼å’Œæœ€å¤§å€¼
    for (let i = 0; i < audioDataRef.current.length; i++) {
      const value = audioDataRef.current[i];
      sum += value;
      max = Math.max(max, value);
      if (value > 0) count++;
    }
    
    const average = sum / audioDataRef.current.length;
    
    // æé«˜æ•æ„Ÿåº¦ï¼šå¢åŠ æƒé‡ï¼Œæé«˜å¢ç›Š
    let level = Math.max(average, max * 0.7);
    level = (level / 255) * 100 * 1.2;
    
    // é™ä½æœ€å°é˜ˆå€¼ï¼Œå…è®¸æ›´å°çš„å£°éŸ³è¢«æ£€æµ‹
    if (level < 1) level = 0;
    
    // å‡å°‘å¹³æ»‘å¤„ç†ï¼Œè®©å˜åŒ–æ›´æ•æ„Ÿ
    const currentLevel = audioLevel;
    const smoothedLevel = currentLevel * 0.7 + level * 0.3;
    
    setAudioLevel(smoothedLevel);
    
    if (isAnalyzingRef.current) {
      animationFrameRef.current = requestAnimationFrame(analyzeAudio);
    }
  };

  // æ¸…ç†éŸ³é¢‘åˆ†æå™¨
  const cleanupAudioAnalyser = () => {
    // åœæ­¢åˆ†æï¼ˆä½¿ç”¨refå’Œstateéƒ½æ›´æ–°ï¼‰
    isAnalyzingRef.current = false;
    setIsAnalyzing(false);
    
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }
    audioAnalyserRef.current = null;
    audioDataRef.current = null;
    setAudioLevel(0);
  };

  // æ–°å¢çŠ¶æ€ï¼šæ»‘åŠ¨æ‰‹åŠ¿æ£€æµ‹
  const [gestureType, setGestureType] = useState<'none' | 'cancel' | 'fill-text'>('none');
  const [showGestureHint, setShowGestureHint] = useState(false);
  const gestureTypeRef = useRef<'none' | 'cancel' | 'fill-text'>('none');

  // åˆå§‹åŒ–å¤šæ¨¡æ€çŠ¶æ€
  const loadMultimodalStatus = async () => {
    try {
      const response = await apiClient.get('/ai/multimodal/status');
      if (response?.success && response?.data) {
        setMultimodalStatus(response.data);
      }
    } catch (error) {
      console.error('è·å–å¤šæ¨¡æ€AIçŠ¶æ€å¤±è´¥:', error);
    }
  };

  // å¼€å§‹å½•éŸ³ï¼ˆé•¿æŒ‰å¼€å§‹ï¼‰
  const startRecording = async () => {
    if (!accountBookId) {
      toast.error('è¯·å…ˆé€‰æ‹©è´¦æœ¬');
      return;
    }

    try {
      if (!isMediaRecordingSupported()) {
        showError(createError(
          MultimodalErrorType.PLATFORM_NOT_SUPPORTED,
          'å½“å‰è®¾å¤‡ä¸æ”¯æŒå½•éŸ³åŠŸèƒ½'
        ));
        return;
      }

      // é¦–å…ˆè¯·æ±‚éº¦å…‹é£æƒé™
      console.log('ğŸ¤ å¼€å§‹è¯·æ±‚éº¦å…‹é£æƒé™...');
      const permissionResult = await ensureMicrophonePermission();
      
      if (!permissionResult.granted) {
        console.error('ğŸ¤ éº¦å…‹é£æƒé™è¢«æ‹’ç»:', permissionResult.error);
        
        // æ£€æŸ¥å½“å‰ç¯å¢ƒ
        const isAndroid = typeof window !== 'undefined' && 
                         (window as any).Capacitor?.getPlatform?.() === 'android';
        
        if (permissionResult.canRetry) {
          showError(createError(
            MultimodalErrorType.PERMISSION_DENIED,
            permissionResult.error || 'éº¦å…‹é£æƒé™è¢«æ‹’ç»'
          ));
          
          // å¦‚æœæ˜¯Androidç¯å¢ƒï¼Œæ˜¾ç¤ºè¯¦ç»†çš„æƒé™æŒ‡å¯¼
          if (isAndroid) {
            setTimeout(() => {
              showPermissionGuide(true);
            }, 2000);
          }
        } else {
          showError(createError(
            MultimodalErrorType.PLATFORM_NOT_SUPPORTED,
            permissionResult.error || 'éº¦å…‹é£åŠŸèƒ½ä¸å¯ç”¨'
          ));
        }
        return;
      }

      console.log('ğŸ¤ éº¦å…‹é£æƒé™è·å–æˆåŠŸï¼Œå¼€å§‹å½•éŸ³...');
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      
      // è®¾ç½®éŸ³é¢‘åˆ†æå™¨
      setupAudioAnalyser(stream);
      
      const chunks: Blob[] = [];
      audioChunksRef.current = chunks;
      
      // è·å–æœ€ä½³éŸ³é¢‘æ ¼å¼
      const bestFormat = getBestAudioFormat();
      console.log('ğŸ¤ [StartRecording] ä½¿ç”¨éŸ³é¢‘æ ¼å¼:', bestFormat);
      
      const recorder = new MediaRecorder(stream, {
        mimeType: bestFormat
      });

      // æ·»åŠ è¶…æ—¶ä¿æŠ¤
      const recordingTimeout = setTimeout(() => {
        console.log('ğŸ¤ [StartRecording] å½•éŸ³è¶…æ—¶ï¼Œè‡ªåŠ¨åœæ­¢');
        if (recorder.state === 'recording') {
          recorder.stop();
        }
      }, 60000); // 60ç§’è¶…æ—¶

      recorder.ondataavailable = (event) => {
        console.log('ğŸ¤ [MediaRecorder] æ•°æ®å¯ç”¨:', event.data.size);
        if (event.data.size > 0) {
          chunks.push(event.data);
        }
      };

      recorder.onstop = () => {
        console.log('ğŸ¤ [MediaRecorder] å½•éŸ³åœæ­¢äº‹ä»¶è§¦å‘');
        clearTimeout(recordingTimeout);
        
        // æ¸…ç†éŸ³é¢‘åˆ†æå™¨
        cleanupAudioAnalyser();
        
        // åœæ­¢æ‰€æœ‰éŸ³é¢‘è½¨é“
        stream.getTracks().forEach(track => {
          console.log('ğŸ¤ [MediaRecorder] åœæ­¢éŸ³é¢‘è½¨é“:', track.label);
          track.stop();
        });

        // ç¡®ä¿UIçŠ¶æ€æ›´æ–°
        setIsRecording(false);
        setMediaRecorder(null);
        setIsButtonTouched(false);

        // ä½¿ç”¨ ref æ¥æ£€æŸ¥å–æ¶ˆçŠ¶æ€ï¼Œé¿å…é—­åŒ…é—®é¢˜
        const currentChunks = audioChunksRef.current;
        const currentGestureType = gestureTypeRef.current;
        console.log('ğŸ¤ [MediaRecorder] æ£€æŸ¥çŠ¶æ€:', {
          recordingCancelled: recordingCancelledRef.current,
          chunksLength: currentChunks?.length || 0,
          gestureType: currentGestureType
        });
        
        if (!recordingCancelledRef.current && currentChunks && currentChunks.length > 0) {
          console.log('ğŸ¤ [MediaRecorder] å¼€å§‹è¯­éŸ³è¯†åˆ«ï¼ŒéŸ³é¢‘å—æ•°:', currentChunks.length, 'æ‰‹åŠ¿ç±»å‹:', currentGestureType);
          // ä½¿ç”¨ç¬¬ä¸€ä¸ªéŸ³é¢‘å—çš„ç±»å‹ä½œä¸ºblobç±»å‹ï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç webm
          const audioBlob = new Blob(currentChunks, { type: currentChunks[0]?.type || 'audio/webm' });
          handleSpeechRecognition(audioBlob, currentGestureType);
        } else {
          console.log('ğŸ¤ [MediaRecorder] è·³è¿‡è¯­éŸ³è¯†åˆ«ï¼Œå–æ¶ˆçŠ¶æ€:', recordingCancelledRef.current, 'éŸ³é¢‘å—æ•°:', currentChunks?.length || 0);
        }
        
        // åœ¨å¤„ç†å®Œæˆåé‡ç½®æ‰‹åŠ¿çŠ¶æ€
        setTimeout(() => {
          gestureTypeRef.current = 'none';
        }, 100);
      };

      recorder.onerror = (event) => {
        console.error('ğŸ¤ [MediaRecorder] å½•éŸ³é”™è¯¯:', event);
        clearTimeout(recordingTimeout);
        
        // æ¸…ç†èµ„æº
        stream.getTracks().forEach(track => track.stop());
        setIsRecording(false);
        setMediaRecorder(null);
        
        showError(createError(
          MultimodalErrorType.RECORDING_FAILED,
          'å½•éŸ³è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯'
        ));
      };

      recorder.start();
      setMediaRecorder(recorder);
      setAudioChunks(chunks);
      setIsRecording(true);
      setRecordingCancelled(false);
      recordingCancelledRef.current = false;
      
      // é‡ç½®æ‰‹åŠ¿çŠ¶æ€
      setGestureType('none');
      gestureTypeRef.current = 'none';
      setShowGestureHint(false);

      console.log('ğŸ¤ [StartRecording] å½•éŸ³å·²å¯åŠ¨ï¼ŒçŠ¶æ€:', recorder.state);
      showInfo('æ­£åœ¨å½•éŸ³ï¼Œæ¾å¼€åœæ­¢ï¼Œå‘ä¸Šæ»‘åŠ¨å–æ¶ˆ');
    } catch (error) {
      console.error('å¯åŠ¨å½•éŸ³å¤±è´¥:', error);
      
      // ç¡®ä¿çŠ¶æ€é‡ç½®
      setIsRecording(false);
      setMediaRecorder(null);
      
      showError(error);
    }
  };

  // åœæ­¢å½•éŸ³ï¼ˆæ¾å¼€æ‰‹æŒ‡ï¼‰
  const stopRecording = (gestureType: 'none' | 'cancel' | 'fill-text' = 'none') => {
    console.log('ğŸ¤ [StopRecording] è°ƒç”¨åœæ­¢å½•éŸ³ï¼Œå½“å‰çŠ¶æ€:', {
      mediaRecorder: mediaRecorder?.state,
      isRecording,
      recordingCancelled,
      gestureType
    });
    
    // ç¡®ä¿æ‰‹åŠ¿ç±»å‹åŒæ­¥åˆ° ref
    gestureTypeRef.current = gestureType;
    
    if (mediaRecorder && mediaRecorder.state === 'recording') {
      console.log('ğŸ¤ [StopRecording] æ­£åœ¨åœæ­¢MediaRecorder...');
      mediaRecorder.stop();
    }
    
    // ç«‹å³æ›´æ–°UIçŠ¶æ€
    setIsRecording(false);
    setMediaRecorder(null);
    setIsButtonTouched(false);
    setTouchStartPos(null);
    
    // æ³¨æ„ï¼šä¸åœ¨è¿™é‡Œæ¸…ç†éŸ³é¢‘åˆ†æå™¨ï¼Œè®©å®ƒåœ¨MediaRecorder.onstopä¸­æ¸…ç†
    
    console.log('ğŸ¤ [StopRecording] å½•éŸ³çŠ¶æ€å·²é‡ç½®');
  };

  // å–æ¶ˆå½•éŸ³
  const cancelRecording = () => {
    console.log('ğŸ¤ [CancelRecording] å–æ¶ˆå½•éŸ³');
    setRecordingCancelled(true);
    recordingCancelledRef.current = true;
    
    // æ¸…ç©ºéŸ³é¢‘å—æ•°æ®ï¼Œç¡®ä¿ä¸ä¼šè¢«å¤„ç†
    audioChunksRef.current = [];
    
    if (mediaRecorder && mediaRecorder.state === 'recording') {
      console.log('ğŸ¤ [CancelRecording] åœæ­¢MediaRecorder...');
      mediaRecorder.stop();
    }
    
    // ç«‹å³æ›´æ–°UIçŠ¶æ€
    setIsRecording(false);
    setMediaRecorder(null);
    setIsButtonTouched(false);
    setTouchStartPos(null);
    
    // æ³¨æ„ï¼šä¸åœ¨è¿™é‡Œæ¸…ç†éŸ³é¢‘åˆ†æå™¨ï¼Œè®©å®ƒåœ¨MediaRecorder.onstopä¸­æ¸…ç†
    
    showInfo('å½•éŸ³å·²å–æ¶ˆ');
    
    console.log('ğŸ¤ [CancelRecording] å½•éŸ³å·²å–æ¶ˆï¼ŒçŠ¶æ€å·²é‡ç½®');
  };

  // å¤„ç†è§¦æ‘¸å¼€å§‹
  const handleTouchStart = (e: React.TouchEvent) => {
    e.preventDefault();
    console.log('ğŸ¤ [TouchStart] è§¦æ‘¸å¼€å§‹');
    const touch = e.touches[0];
    setTouchStartPos({ x: touch.clientX, y: touch.clientY });
    setIsButtonTouched(true);
    startRecording();
  };

  // å¤„ç†è§¦æ‘¸ç§»åŠ¨ï¼ˆæ£€æµ‹æ˜¯å¦è¦å–æ¶ˆï¼‰
  const handleTouchMove = (e: React.TouchEvent) => {
    if (!touchStartPos || !isRecording) return;

    const touch = e.touches[0];
    const deltaY = touchStartPos.y - touch.clientY;
    const deltaX = Math.abs(touch.clientX - touchStartPos.x);

    //console.log('ğŸ¤ [TouchMove] è§¦æ‘¸ç§»åŠ¨:', { deltaY, deltaX });

    // æ£€æµ‹æ‰‹åŠ¿ç±»å‹
    if (Math.abs(deltaY) > 30 && deltaX < 50) { // å‚ç›´æ»‘åŠ¨ï¼Œæ°´å¹³åç§»ä¸è¶…è¿‡50px
      if (deltaY > 50) {
        // å‘ä¸Šæ»‘åŠ¨ - å–æ¶ˆå½•éŸ³
        if (gestureTypeRef.current !== 'cancel') {
          setGestureType('cancel');
          gestureTypeRef.current = 'cancel';
          setShowGestureHint(true);
          console.log('ğŸ¤ [TouchMove] æ£€æµ‹åˆ°å–æ¶ˆæ‰‹åŠ¿');
        }
      } else if (deltaY < -50) {
        // å‘ä¸‹æ»‘åŠ¨ - å¡«å…¥æ–‡æœ¬æ¡†
        if (gestureTypeRef.current !== 'fill-text') {
          setGestureType('fill-text');
          gestureTypeRef.current = 'fill-text';
          setShowGestureHint(true);
          console.log('ğŸ¤ [TouchMove] æ£€æµ‹åˆ°å¡«å…¥æ–‡æœ¬æ‰‹åŠ¿');
        }
      }
    } else if (Math.abs(deltaY) < 30) {
      // æ²¡æœ‰æ˜æ˜¾çš„å‚ç›´æ»‘åŠ¨
      if (gestureTypeRef.current !== 'none') {
        setGestureType('none');
        gestureTypeRef.current = 'none';
        setShowGestureHint(false);
      }
    }
  };

  // å¤„ç†è§¦æ‘¸ç»“æŸ
  const handleTouchEnd = (e: React.TouchEvent) => {
    e.preventDefault();
    console.log('ğŸ¤ [TouchEnd] è§¦æ‘¸ç»“æŸï¼Œå½“å‰çŠ¶æ€:', { isRecording, recordingCancelled, gestureType });
    
    setIsButtonTouched(false);
    
    if (isRecording && !recordingCancelled) {
      if (gestureType === 'cancel') {
        // ä¸Šæ»‘å–æ¶ˆå½•éŸ³
        console.log('ğŸ¤ [TouchEnd] æ‰§è¡Œå–æ¶ˆå½•éŸ³');
        cancelRecording();
      } else {
        // æ¾å¼€åœæ­¢å½•éŸ³ï¼Œæ ¹æ®æ‰‹åŠ¿ç±»å‹å†³å®šåç»­æ“ä½œ
        console.log('ğŸ¤ [TouchEnd] æ­£å¸¸ç»“æŸå½•éŸ³ï¼Œæ‰‹åŠ¿ç±»å‹:', gestureType);
        stopRecording(gestureType);
      }
    } else {
      console.log('ğŸ¤ [TouchEnd] å½•éŸ³å·²å–æ¶ˆæˆ–æœªåœ¨å½•éŸ³çŠ¶æ€');
    }

    // é‡ç½®æ‰‹åŠ¿çŠ¶æ€
    setGestureType('none');
    // æ³¨æ„ï¼šä¸è¦ç«‹å³é‡ç½® gestureTypeRef.currentï¼Œå› ä¸º MediaRecorder.onstop å¯èƒ½è¿˜æ²¡æœ‰æ‰§è¡Œ
    // gestureTypeRef.current å°†åœ¨ MediaRecorder.onstop äº‹ä»¶å¤„ç†å®Œæˆåé‡ç½®
    setShowGestureHint(false);
  };

  // å¤„ç†é¼ æ ‡äº‹ä»¶ï¼ˆæ¡Œé¢ç«¯ï¼‰
  const handleMouseDown = (e: React.MouseEvent) => {
    e.preventDefault();
    console.log('ğŸ¤ [MouseDown] é¼ æ ‡æŒ‰ä¸‹');
    setTouchStartPos({ x: e.clientX, y: e.clientY });
    setIsButtonTouched(true);
    startRecording();
  };

  const handleMouseMove = (e: React.MouseEvent) => {
    if (!touchStartPos || !isRecording) return;

    const deltaY = touchStartPos.y - e.clientY;
    const deltaX = Math.abs(e.clientX - touchStartPos.x);

    console.log('ğŸ¤ [MouseMove] é¼ æ ‡ç§»åŠ¨:', { deltaY, deltaX });

    // æ£€æµ‹æ‰‹åŠ¿ç±»å‹ï¼ˆä¸è§¦æ‘¸ç›¸åŒï¼‰
    if (Math.abs(deltaY) > 30 && deltaX < 50) { // å‚ç›´ç§»åŠ¨ï¼Œæ°´å¹³åç§»ä¸è¶…è¿‡50px
      if (deltaY > 50) {
        // å‘ä¸Šç§»åŠ¨ - å–æ¶ˆå½•éŸ³
        if (gestureTypeRef.current !== 'cancel') {
          setGestureType('cancel');
          gestureTypeRef.current = 'cancel';
          setShowGestureHint(true);
          console.log('ğŸ¤ [MouseMove] æ£€æµ‹åˆ°å–æ¶ˆæ‰‹åŠ¿');
        }
      } else if (deltaY < -50) {
        // å‘ä¸‹ç§»åŠ¨ - å¡«å…¥æ–‡æœ¬æ¡†
        if (gestureTypeRef.current !== 'fill-text') {
          setGestureType('fill-text');
          gestureTypeRef.current = 'fill-text';
          setShowGestureHint(true);
          console.log('ğŸ¤ [MouseMove] æ£€æµ‹åˆ°å¡«å…¥æ–‡æœ¬æ‰‹åŠ¿');
        }
      }
    } else if (Math.abs(deltaY) < 30) {
      // æ²¡æœ‰æ˜æ˜¾çš„å‚ç›´ç§»åŠ¨
      if (gestureTypeRef.current !== 'none') {
        setGestureType('none');
        gestureTypeRef.current = 'none';
        setShowGestureHint(false);
      }
    }
  };

  const handleMouseUp = (e: React.MouseEvent) => {
    e.preventDefault();
    console.log('ğŸ¤ [MouseUp] é¼ æ ‡é‡Šæ”¾ï¼Œå½“å‰çŠ¶æ€:', { isRecording, recordingCancelled, gestureType });
    
    setIsButtonTouched(false);
    
    if (isRecording && !recordingCancelled) {
      if (gestureType === 'cancel') {
        // ä¸Šç§»å–æ¶ˆå½•éŸ³
        console.log('ğŸ¤ [MouseUp] æ‰§è¡Œå–æ¶ˆå½•éŸ³');
        cancelRecording();
      } else {
        // æ¾å¼€åœæ­¢å½•éŸ³ï¼Œæ ¹æ®æ‰‹åŠ¿ç±»å‹å†³å®šåç»­æ“ä½œ
        console.log('ğŸ¤ [MouseUp] æ­£å¸¸ç»“æŸå½•éŸ³ï¼Œæ‰‹åŠ¿ç±»å‹:', gestureType);
        stopRecording(gestureType);
      }
    } else {
      console.log('ğŸ¤ [MouseUp] å½•éŸ³å·²å–æ¶ˆæˆ–æœªåœ¨å½•éŸ³çŠ¶æ€');
    }

    // é‡ç½®æ‰‹åŠ¿çŠ¶æ€
    setGestureType('none');
    // æ³¨æ„ï¼šä¸è¦ç«‹å³é‡ç½® gestureTypeRef.currentï¼Œå› ä¸º MediaRecorder.onstop å¯èƒ½è¿˜æ²¡æœ‰æ‰§è¡Œ
    // gestureTypeRef.current å°†åœ¨ MediaRecorder.onstop äº‹ä»¶å¤„ç†å®Œæˆåé‡ç½®
    setShowGestureHint(false);
  };

  // å¤„ç†è¯­éŸ³è¯†åˆ«
  const handleSpeechRecognition = async (audioBlob: Blob, gestureType: 'none' | 'cancel' | 'fill-text') => {
    console.log('ğŸ¤ [SpeechRecognition] å¼€å§‹å¤„ç†è¯­éŸ³è¯†åˆ«ï¼Œæ‰‹åŠ¿ç±»å‹:', gestureType);
    
    if (!accountBookId) {
      toast.error('è¯·å…ˆé€‰æ‹©è´¦æœ¬');
      return;
    }

    setIsProcessingMultimodal(true);

    try {
      // æ£€æµ‹éŸ³é¢‘æ ¼å¼å¹¶è‡ªåŠ¨è½¬æ¢
      const audioFormat = detectAudioFormat(audioBlob);
      console.log('ğŸ¤ [SpeechRecognition] æ£€æµ‹åˆ°éŸ³é¢‘æ ¼å¼:', audioFormat, 'å¤§å°:', audioBlob.size);
      
      let processedAudio = audioBlob;
      let fileName = `recording.${audioFormat}`;
      
      // å¦‚æœéœ€è¦è½¬æ¢æ ¼å¼
      if (needsConversion(audioFormat)) {
        console.log('ğŸ¤ [SpeechRecognition] éœ€è¦è½¬æ¢éŸ³é¢‘æ ¼å¼');
        //showInfo('æ­£åœ¨å¤„ç†éŸ³é¢‘æ ¼å¼...');
        
        try {
          const conversionResult = await processAudioForSpeechRecognition(audioBlob);
          processedAudio = conversionResult.blob;
          fileName = `recording.${conversionResult.format}`;
          
          console.log('ğŸ¤ [SpeechRecognition] éŸ³é¢‘è½¬æ¢å®Œæˆ:', {
            åŸå§‹å¤§å°: audioBlob.size,
            è½¬æ¢åå¤§å°: conversionResult.size,
            è½¬æ¢æ—¶é—´: `${conversionResult.duration}ms`,
            æ ¼å¼: `${audioFormat} â†’ ${conversionResult.format}`
          });
          
          //showSuccess(`éŸ³é¢‘å·²è½¬æ¢ä¸º${conversionResult.format.toUpperCase()}æ ¼å¼`);
        } catch (conversionError) {
          console.error('ğŸ¤ [SpeechRecognition] éŸ³é¢‘è½¬æ¢å¤±è´¥:', conversionError);
          showError(`éŸ³é¢‘æ ¼å¼è½¬æ¢å¤±è´¥: ${conversionError instanceof Error ? conversionError.message : 'æœªçŸ¥é”™è¯¯'}`);
          return;
        }
      } else {
        console.log('ğŸ¤ [SpeechRecognition] éŸ³é¢‘æ ¼å¼å·²æ”¯æŒï¼Œæ— éœ€è½¬æ¢');
      }

      const formData = new FormData();
      formData.append('audio', processedAudio, fileName);
      formData.append('accountBookId', accountBookId);

      const response = await apiClient.post('/ai/smart-accounting/speech', formData, {
        headers: {
          'Content-Type': 'multipart/form-data',
        },
        timeout: 60000,
      });

      if (response && response.data && response.data.text) {
        const recognizedText = response.data.text;
        
        // æ ¹æ®æ‰‹åŠ¿ç±»å‹æ‰§è¡Œä¸åŒæ“ä½œ
        if (gestureType === 'cancel') {
          // å–æ¶ˆå½•éŸ³çš„æƒ…å†µä¸‹ï¼Œä¸åº”è¯¥åˆ°è¿™é‡Œï¼Œè¿™é‡Œåªæ˜¯ä¿æŠ¤æ€§ä»£ç 
          console.log('ğŸ¤ [SpeechRecognition] å½•éŸ³å·²å–æ¶ˆï¼Œè·³è¿‡å¤„ç†');
          return;
        } else if (gestureType === 'fill-text') {
          // ä¸‹æ»‘æ‰‹åŠ¿ï¼šä»…å¡«å…¥æ–‡æœ¬æ¡†ï¼Œä¸è‡ªåŠ¨è°ƒç”¨è®°è´¦
          console.log('ğŸ¤ [SpeechRecognition] ä¸‹æ»‘æ‰‹åŠ¿ï¼šä»…å¡«å…¥æ–‡æœ¬æ¡†');
          setDescription(recognizedText);
          //showSuccess('è¯­éŸ³å·²è½¬æ¢ä¸ºæ–‡å­—');
          // æ³¨æ„ï¼šè¿™é‡Œä¸è°ƒç”¨ä»»ä½•è®°è´¦é€»è¾‘
        } else {
          // æ­£å¸¸æ¾å¼€æ‰‹åŠ¿ï¼šç›´æ¥è°ƒç”¨è®°è´¦
          console.log('ğŸ¤ [SpeechRecognition] æ­£å¸¸æ¾å¼€æ‰‹åŠ¿ï¼šç›´æ¥è®°è´¦');
          
          // ç”Ÿæˆå”¯ä¸€è¿›åº¦ID
          const progressId = `voice-direct-add-${Date.now()}`;
          
          // è·å–æ™ºèƒ½è®°è´¦è¿›åº¦ç®¡ç†å™¨å®ä¾‹
          const progressManager = SmartAccountingProgressManager.getInstance();
          
          // æ˜¾ç¤ºè¿›åº¦é€šçŸ¥å¹¶ç«‹å³å…³é—­æ¨¡æ€æ¡†
          progressManager.showProgress(progressId, 'æ­£åœ¨å¯åŠ¨æ™ºèƒ½è®°è´¦...');
          onClose(); // ç«‹å³å…³é—­æ¨¡æ€æ¡†
          
          // è®¾ç½®è¯†åˆ«çš„æ–‡æœ¬åˆ°æè¿°æ¡†ï¼ˆä¸ºäº†ä¿æŒä¸€è‡´æ€§ï¼‰
          setDescription(recognizedText);
          
          // è°ƒç”¨ç›´æ¥æ·»åŠ è®°è´¦API
          try {
            const response = await apiClient.post(
              `/ai/account/${accountBookId}/smart-accounting/direct`,
              { description: recognizedText },
              { timeout: 60000 }
            );

            if (response && response.id) {
              progressManager.showProgress(progressId, 'è®°è´¦æˆåŠŸ', 'success');

              // åˆ·æ–°ä»ªè¡¨ç›˜æ•°æ®
              if (accountBookId) {
                try {
                  await refreshDashboardData(accountBookId);
                } catch (refreshError) {
                  console.error('åˆ·æ–°ä»ªè¡¨ç›˜æ•°æ®å¤±è´¥:', refreshError);
                }
              }

              // æ¸…ç©ºæè¿°
              setDescription('');
            } else {
              progressManager.showProgress(progressId, 'è®°è´¦å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨å¡«å†™', 'error');
            }
          } catch (error: any) {
            console.error('è¯­éŸ³ç›´æ¥è®°è´¦å¤±è´¥:', error);
            
            let errorMessage = 'è®°è´¦å¤±è´¥ï¼Œè¯·é‡è¯•';
            
            if (error.response) {
              const errorData = error.response.data;
              if (error.response.status === 429 && errorData?.type === 'TOKEN_LIMIT_EXCEEDED') {
                errorMessage = `${errorData.error || 'Tokenä½¿ç”¨é‡å·²è¾¾é™é¢ï¼Œè¯·ç¨åå†è¯•'}`;
              } else if (errorData?.info && errorData.info.includes('è®°è´¦æ— å…³')) {
                errorMessage = 'æ‚¨çš„æè¿°ä¼¼ä¹ä¸è®°è´¦æ— å…³ï¼Œè¯·å°è¯•æè¿°å…·ä½“çš„æ¶ˆè´¹æˆ–æ”¶å…¥æƒ…å†µ';
              } else {
                errorMessage = `è®°è´¦å¤±è´¥: ${errorData?.error || errorData?.message || 'æœåŠ¡å™¨é”™è¯¯'}`;
              }
            } else if (error.request) {
              errorMessage = 'ç½‘ç»œè¿æ¥å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥ç½‘ç»œåé‡è¯•';
            }
            
            progressManager.showProgress(progressId, errorMessage, 'error');
          }
        }
      } else {
        showError(createError(
          MultimodalErrorType.RECOGNITION_FAILED,
          'è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•'
        ));
      }
    } catch (error: any) {
      console.error('è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
      showError(error);
    } finally {
      setIsProcessingMultimodal(false);
    }
  };

  // å¤„ç†å›¾ç‰‡è®°è´¦
  const handleImageRecording = () => {
    if (!accountBookId) {
      toast.error('è¯·å…ˆé€‰æ‹©è´¦æœ¬');
      return;
    }

    if (!isFileSelectionSupported()) {
      showError(createError(
        MultimodalErrorType.PLATFORM_NOT_SUPPORTED,
        'å½“å‰è®¾å¤‡ä¸æ”¯æŒæ–‡ä»¶é€‰æ‹©åŠŸèƒ½'
      ));
      return;
    }

    fileInputRef.current?.click();
  };

  // å¤„ç†å›¾ç‰‡é€‰æ‹©
  const handleImageSelect = (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (!file) return;

    // éªŒè¯æ–‡ä»¶æ ¼å¼
    if (!file.type.startsWith('image/')) {
      showError(createError(
        MultimodalErrorType.INVALID_FILE_FORMAT,
        'è¯·é€‰æ‹©å›¾ç‰‡æ–‡ä»¶'
      ));
      return;
    }

    handleImageRecognition(file);
  };

  // å¤„ç†å›¾ç‰‡è¯†åˆ«
  const handleImageRecognition = async (imageFile: File) => {
    if (!accountBookId) {
      toast.error('è¯·å…ˆé€‰æ‹©è´¦æœ¬');
      return;
    }

    setIsProcessingMultimodal(true);

    try {
      const formData = new FormData();
      formData.append('image', imageFile);
      formData.append('accountBookId', accountBookId);

      const response = await apiClient.post('/ai/smart-accounting/vision', formData, {
        headers: {
          'Content-Type': 'multipart/form-data',
        },
        timeout: 60000,
      });

      if (response && response.data && response.data.text) {
        const recognizedText = response.data.text;
        setDescription(recognizedText);
        showSuccess('å›¾ç‰‡è¯†åˆ«æˆåŠŸ');

        // è‡ªåŠ¨è°ƒç”¨æ™ºèƒ½è®°è´¦
        await handleSmartAccountingWithText(recognizedText);
      } else {
        showError(createError(
          MultimodalErrorType.RECOGNITION_FAILED,
          'å›¾ç‰‡è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•'
        ));
      }
    } catch (error: any) {
      console.error('å›¾ç‰‡è¯†åˆ«å¤±è´¥:', error);
      showError(error);
    } finally {
      setIsProcessingMultimodal(false);
      // æ¸…é™¤æ–‡ä»¶è¾“å…¥
      if (fileInputRef.current) {
        fileInputRef.current.value = '';
      }
    }
  };

  // ä½¿ç”¨è¯†åˆ«çš„æ–‡æœ¬è¿›è¡Œæ™ºèƒ½è®°è´¦
  const handleSmartAccountingWithText = async (text: string) => {
    try {
      setIsProcessing(true);
      setProcessingStep('æ­£åœ¨åˆ†æè®°è´¦ä¿¡æ¯...');

      const response = await apiClient.post(
        `/ai/account/${accountBookId}/smart-accounting`,
        { description: text },
        { timeout: 60000 }
      );

      if (response) {
        // å°†ç»“æœå­˜å‚¨åˆ°sessionStorageï¼Œä¾›æ·»åŠ äº¤æ˜“é¡µé¢ä½¿ç”¨
        sessionStorage.setItem('smartAccountingResult', JSON.stringify(response));
        showSuccess('æ™ºèƒ½è¯†åˆ«æˆåŠŸ');
        onClose();
        router.push('/transactions/new');
      } else {
        showError(createError(
          MultimodalErrorType.PROCESSING_ERROR,
          'æ™ºèƒ½è¯†åˆ«å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨å¡«å†™'
        ));
      }
    } catch (error: any) {
      console.error('æ™ºèƒ½è®°è´¦å¤±è´¥:', error);

      if (error.response?.data?.info && error.response.data.info.includes('è®°è´¦æ— å…³')) {
        showInfo('æ‚¨çš„æè¿°ä¼¼ä¹ä¸è®°è´¦æ— å…³ï¼Œè¯·å°è¯•æè¿°å…·ä½“çš„æ¶ˆè´¹æˆ–æ”¶å…¥æƒ…å†µ');
      } else {
        showError(error);
      }
    } finally {
      setIsProcessing(false);
      setProcessingStep('');
    }
  };

  // æ™ºèƒ½è®°è´¦
  const handleSmartAccounting = async () => {
    if (!description.trim()) {
      toast.error('è¯·è¾“å…¥æè¿°');
      return;
    }

    await handleSmartAccountingWithText(description.trim());
  };

  // å¤„ç†ç›´æ¥æ·»åŠ è®°è´¦
  const handleDirectAdd = async () => {
    if (!description.trim()) {
      toast.error('è¯·è¾“å…¥æè¿°');
      return;
    }

    if (!accountBookId) {
      toast.error('è¯·å…ˆé€‰æ‹©è´¦æœ¬');
      return;
    }

    // ç”Ÿæˆå”¯ä¸€è¿›åº¦ID
    const progressId = `direct-add-${Date.now()}`;
    
    // è·å–æ™ºèƒ½è®°è´¦è¿›åº¦ç®¡ç†å™¨å®ä¾‹
    const progressManager = SmartAccountingProgressManager.getInstance();
    
    // æ˜¾ç¤ºè¿›åº¦é€šçŸ¥å¹¶ç«‹å³å…³é—­æ¨¡æ€æ¡†
    progressManager.showProgress(progressId, 'æ­£åœ¨å¯åŠ¨æ™ºèƒ½è®°è´¦...');
    onClose(); // ç«‹å³å…³é—­æ¨¡æ€æ¡†

    try {
      // è°ƒç”¨ç›´æ¥æ·»åŠ è®°è´¦API
      const response = await apiClient.post(
        `/ai/account/${accountBookId}/smart-accounting/direct`,
        { description },
        { timeout: 60000 }
      );

      if (response && response.id) {
        progressManager.showProgress(progressId, 'è®°è´¦æˆåŠŸ', 'success');

        // åˆ·æ–°ä»ªè¡¨ç›˜æ•°æ®
        if (accountBookId) {
          try {
            await refreshDashboardData(accountBookId);
          } catch (refreshError) {
            console.error('åˆ·æ–°ä»ªè¡¨ç›˜æ•°æ®å¤±è´¥:', refreshError);
          }
        }

        setDescription('');
      } else {
        progressManager.showProgress(progressId, 'è®°è´¦å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨å¡«å†™', 'error');
      }
    } catch (error: any) {
      console.error('ç›´æ¥æ·»åŠ è®°è´¦å¤±è´¥:', error);

      let errorMessage = 'è®°è´¦å¤±è´¥ï¼Œè¯·é‡è¯•';

      if (error.response) {
        const errorData = error.response.data;

        if (error.response.status === 429 && errorData?.type === 'TOKEN_LIMIT_EXCEEDED') {
          errorMessage = `${errorData.error || 'Tokenä½¿ç”¨é‡å·²è¾¾é™é¢ï¼Œè¯·ç¨åå†è¯•'}`;
        } else if (errorData?.info && errorData.info.includes('è®°è´¦æ— å…³')) {
          errorMessage = 'æ‚¨çš„æè¿°ä¼¼ä¹ä¸è®°è´¦æ— å…³ï¼Œè¯·å°è¯•æè¿°å…·ä½“çš„æ¶ˆè´¹æˆ–æ”¶å…¥æƒ…å†µ';
        } else {
          errorMessage = `è®°è´¦å¤±è´¥: ${errorData?.error || errorData?.message || 'æœåŠ¡å™¨é”™è¯¯'}`;
        }
      } else if (error.request) {
        errorMessage = 'ç½‘ç»œè¿æ¥å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥ç½‘ç»œåé‡è¯•';
      }

      progressManager.showProgress(progressId, errorMessage, 'error');
    }
  };

  // æ‰‹åŠ¨è®°è´¦
  const handleManualAccounting = () => {
    onClose();
    router.push('/transactions/new');
  };

  // æ¸…é™¤å›¾ç‰‡é€‰æ‹©
  const clearImageSelection = () => {
    setSelectedImage(null);
    setImagePreview(null);
    if (fileInputRef.current) {
      fileInputRef.current.value = '';
    }
  };

  useEffect(() => {
    if (isOpen) {
      // åˆå§‹åŒ–å¤šæ¨¡æ€çŠ¶æ€
      loadMultimodalStatus();
      
      // ä¿å­˜å½“å‰æ»šåŠ¨ä½ç½®
      const scrollY = window.scrollY;
      const scrollX = window.scrollX;
      
      // ç¦ç”¨èƒŒæ™¯é¡µé¢æ»šåŠ¨ - æ›´å¼ºçš„æ–¹å¼
      const originalStyle = window.getComputedStyle(document.body);
      const originalOverflow = originalStyle.overflow;
      const originalPosition = originalStyle.position;
      const originalTop = originalStyle.top;
      const originalLeft = originalStyle.left;
      const originalWidth = originalStyle.width;
      const originalHeight = originalStyle.height;
      
      // åº”ç”¨æ›´å¼ºçš„æ»šåŠ¨ç¦ç”¨æ ·å¼
      document.body.style.overflow = 'hidden';
      document.body.style.position = 'fixed';
      document.body.style.top = `-${scrollY}px`;
      document.body.style.left = `-${scrollX}px`;
      document.body.style.width = '100vw';
      document.body.style.height = '100vh';
      
      // æ·»åŠ  CSS ç±»ä»¥ç¡®ä¿æ ·å¼ä¼˜å…ˆçº§
      document.body.classList.add('modal-open');
      document.documentElement.classList.add('modal-open');
      
      // åŒæ—¶ç¦ç”¨ html å…ƒç´ çš„æ»šåŠ¨
      const htmlElement = document.documentElement;
      const htmlOriginalOverflow = htmlElement.style.overflow;
      htmlElement.style.overflow = 'hidden';
      
      // é˜»æ­¢æ‰€æœ‰æ»šåŠ¨äº‹ä»¶
      const preventScroll = (e: Event) => {
        e.preventDefault();
        e.stopPropagation();
        return false;
      };
      
      const preventTouchMove = (e: TouchEvent) => {
        // åªé˜»æ­¢éæ¨¡æ€æ¡†å†…çš„è§¦æ‘¸ç§»åŠ¨
        const modalElement = document.querySelector('.smart-accounting-dialog');
        if (modalElement && !modalElement.contains(e.target as Node)) {
          e.preventDefault();
          e.stopPropagation();
          return false;
        }
      };
      
      const preventWheel = (e: WheelEvent) => {
        // åªé˜»æ­¢éæ¨¡æ€æ¡†å†…çš„æ»šè½®äº‹ä»¶
        const modalElement = document.querySelector('.smart-accounting-dialog');
        if (modalElement && !modalElement.contains(e.target as Node)) {
          e.preventDefault();
          e.stopPropagation();
          return false;
        }
      };
      
      // æ·»åŠ äº‹ä»¶ç›‘å¬å™¨
      document.addEventListener('scroll', preventScroll, { passive: false });
      document.addEventListener('touchmove', preventTouchMove, { passive: false });
      document.addEventListener('wheel', preventWheel, { passive: false });
      window.addEventListener('scroll', preventScroll, { passive: false });
      
      return () => {
        // ç§»é™¤äº‹ä»¶ç›‘å¬å™¨
        document.removeEventListener('scroll', preventScroll);
        document.removeEventListener('touchmove', preventTouchMove);
        document.removeEventListener('wheel', preventWheel);
        window.removeEventListener('scroll', preventScroll);
        
        // ç§»é™¤ CSS ç±»
        document.body.classList.remove('modal-open');
        document.documentElement.classList.remove('modal-open');
        
        // æ¢å¤èƒŒæ™¯é¡µé¢æ»šåŠ¨
        document.body.style.overflow = originalOverflow;
        document.body.style.position = originalPosition;
        document.body.style.top = originalTop;
        document.body.style.left = originalLeft;
        document.body.style.width = originalWidth;
        document.body.style.height = originalHeight;
        
        // æ¢å¤ html å…ƒç´ 
        htmlElement.style.overflow = htmlOriginalOverflow;
        
        // æ¢å¤æ»šåŠ¨ä½ç½®
        window.scrollTo(scrollX, scrollY);
      };
    }
    
    // ç»„ä»¶å¸è½½æ—¶æ¸…ç†èµ„æº
    return () => {
      if (isRecording) {
        cleanupAudioAnalyser();
      }
    };
  }, [isOpen, isRecording]);

  if (!isOpen) return null;

  // å¤„ç†ç‚¹å‡»ç©ºç™½å¤„å…³é—­å¼¹çª—
  const handleOverlayClick = (e: React.MouseEvent) => {
    if (e.target === e.currentTarget) {
      onClose();
    }
  };

  return (
    <div 
      className="smart-accounting-dialog-overlay" 
      onClick={handleOverlayClick}
    >
      <div className="smart-accounting-dialog" style={{ position: 'relative' }}>
        <div className="smart-accounting-dialog-header">
          <h3 className="smart-accounting-dialog-title">æ™ºèƒ½è®°è´¦</h3>
          <button className="smart-accounting-dialog-close" onClick={onClose}>
            <XMarkIcon className="w-5 h-5" />
          </button>
        </div>

        {isProcessing ? (
          <div className="smart-accounting-processing">
            <div className="smart-accounting-loading">
              <div className="spinner"></div>
            </div>
            <p className="smart-accounting-processing-text">{processingStep || 'æ­£åœ¨å¤„ç†...'}</p>
          </div>
        ) : (
          <>
            <div className="smart-accounting-dialog-content">
              <p className="smart-accounting-dialog-subtitle">è¾“å…¥ä¸€å¥è¯ï¼Œè‡ªåŠ¨è¯†åˆ«è®°è´¦ä¿¡æ¯</p>

              {/* æ–‡æœ¬è¾“å…¥ */}
              <div className="smart-accounting-input-wrapper">
                <textarea
                  className="smart-accounting-textarea"
                  placeholder="ä¾‹å¦‚ï¼šæ˜¨å¤©åœ¨æ²ƒå°”ç›ä¹°äº†æ—¥ç”¨å“ï¼ŒèŠ±äº†128.5å…ƒ"
                  value={description}
                  onChange={(e) => setDescription(e.target.value)}
                  rows={3}
                  autoFocus
                />
              </div>

              {/* å½•éŸ³çŠ¶æ€æç¤º - åŠ¨æ€å£°æ³¢æ•ˆæœ */}
              {isRecording && (
                <div className="recording-indicator">
                  <div className="sound-wave-container">
                    <div className="microphone-icon">
                      <i className="fas fa-microphone"></i>
                    </div>
                    <div className="sound-waves">
                      {[...Array(7)].map((_, i) => {
                        // åŸºç¡€é«˜åº¦
                        const baseHeight = 15;
                        const maxHeight = 60;
                        
                        // æ£€æµ‹é˜ˆå€¼
                        const hasAudio = audioLevel > 1;
                        
                        // æé«˜éŸ³é‡æ˜ å°„æ•æ„Ÿåº¦
                        const volumeMultiplier = hasAudio ? 
                          Math.pow(audioLevel / 100, 0.5) * (maxHeight - baseHeight) : 0;
                        
                        // å¢åŠ æ³¢å½¢åŠ¨ç”»å¹…åº¦
                        let waveOffset = 0;
                        if (hasAudio) {
                          const frequency = 0.007 + i * 0.003;
                          const phase = i * Math.PI / 3; 
                          const amplitude = Math.max(1, audioLevel * 0.12);
                          waveOffset = Math.sin(animationTime * frequency + phase) * amplitude;
                        }
                        
                        // æœ€ç»ˆé«˜åº¦è®¡ç®—
                        const finalHeight = baseHeight + volumeMultiplier + waveOffset;
                        
                        // ä¼˜åŒ–é¢œè‰²é˜ˆå€¼ï¼Œè®©å˜åŒ–æ›´æ˜æ˜¾
                        let color = '#6b7280'; // é™é»˜æ—¶çš„ç°è‰²
                        if (audioLevel > 30) color = '#ef4444'; // çº¢è‰² - é«˜éŸ³é‡
                        else if (audioLevel > 20) color = '#f59e0b'; // æ©™è‰² - ä¸­é«˜éŸ³é‡  
                        else if (audioLevel > 10) color = '#22c55e'; // ç»¿è‰² - ä¸­éŸ³é‡
                        else if (audioLevel > 5) color = '#3b82f6'; // è“è‰² - ä½éŸ³é‡
                        else if (audioLevel > 1) color = '#8b5cf6'; // ç´«è‰² - æä½éŸ³é‡
                        
                        // æé«˜é€æ˜åº¦å˜åŒ–æ•æ„Ÿåº¦
                        const opacity = hasAudio ? 
                          Math.max(0.7, Math.min(1, 0.7 + audioLevel / 100 * 0.3)) : 0.4;
                        const scale = hasAudio ? 
                          0.9 + (audioLevel / 100) * 0.1 : 0.8;
                        
                        return (
                          <div
                            key={i}
                            className="wave-bar"
                            style={{
                              height: `${finalHeight}px`,
                              backgroundColor: color,
                              opacity: opacity,
                              transform: `scaleY(${scale})`,
                              boxShadow: audioLevel > 15 ? `0 0 6px ${color}60` : 'none',
                              transition: hasAudio ? 'none' : 'all 0.3s ease'
                            }}
                          />
                        );
                      })}
                    </div>
                  </div>
                  <p className="title">
                    æ­£åœ¨å½•éŸ³...
                  </p>
                  {showGestureHint && (
                    <p className="hint gesture-hint">
                      {gestureType === 'cancel' ? 'æ¾å¼€å–æ¶ˆå½•éŸ³' : 
                       gestureType === 'fill-text' ? 'æ¾å¼€å¡«å…¥æ–‡æœ¬æ¡†' : 
                       'æ¾å¼€è½¬æ¢æ–‡å­—å¹¶è®°è´¦'}
                    </p>
                  )}
                  {!showGestureHint && (
                    <p className="default-hint">
                      ä¸Šæ»‘å–æ¶ˆ â€¢ ä¸‹æ»‘å¡«å…¥æ–‡æœ¬æ¡† â€¢ æ¾å¼€ç›´æ¥è®°è´¦
                    </p>
                  )}
                </div>
              )}

              <div className="smart-accounting-buttons">
                <button
                  className="smart-accounting-button identify-button"
                  onClick={handleSmartAccounting}
                  disabled={isProcessing || !description.trim()}
                >
                  æ™ºèƒ½è¯†åˆ«
                </button>

                <button
                  className="smart-accounting-button direct-button"
                  onClick={handleDirectAdd}
                  disabled={!description.trim()}
                >
                  ç›´æ¥æ·»åŠ 
                </button>
              </div>

              <div className="smart-accounting-manual-wrapper">
                {/* éšè—çš„æ–‡ä»¶è¾“å…¥ */}
                <input
                  ref={fileInputRef}
                  type="file"
                  accept="image/*"
                  onChange={handleImageSelect}
                  style={{ display: 'none' }}
                />

                {/* åº•éƒ¨æŒ‰é’®ç»„ï¼šç›¸æœº - æ‰‹åŠ¨è®°è´¦ - éº¦å…‹é£ */}
                <div style={{
                  display: 'flex',
                  gap: '12px',
                  alignItems: 'center'
                }}>
                  {/* ç›¸æœºæŒ‰é’® */}
                  <button
                    type="button"
                    onClick={handleImageRecording}
                    disabled={isProcessing || isProcessingMultimodal}
                    style={{
                      width: '48px',
                      height: '48px',
                      borderRadius: '12px',
                      border: 'none',
                      backgroundColor: 'var(--success-color, #22c55e)',
                      color: 'white',
                      fontSize: '18px',
                      cursor: (isProcessing || isProcessingMultimodal) ? 'not-allowed' : 'pointer',
                      opacity: (isProcessing || isProcessingMultimodal) ? 0.6 : 1,
                      transition: 'all 0.2s ease',
                      display: 'flex',
                      alignItems: 'center',
                      justifyContent: 'center',
                      boxShadow: '0 2px 8px rgba(0, 0, 0, 0.1)'
                    }}
                    title="å›¾ç‰‡è®°è´¦"
                  >
                    {isProcessingMultimodal ? (
                      <i className="fas fa-spinner fa-spin"></i>
                    ) : (
                      <i className="fas fa-camera"></i>
                    )}
                  </button>

                  {/* æ‰‹åŠ¨è®°è´¦æŒ‰é’® */}
                  <button
                    className="smart-accounting-manual-button"
                    onClick={handleManualAccounting}
                    style={{ flex: 1 }}
                  >
                    æ‰‹åŠ¨è®°è´¦
                  </button>

                  {/* éº¦å…‹é£æŒ‰é’® */}
                  <button
                    ref={micButtonRef}
                    type="button"
                    disabled={isProcessing || isProcessingMultimodal}
                    onTouchStart={handleTouchStart}
                    onTouchMove={handleTouchMove}
                    onTouchEnd={handleTouchEnd}
                    onMouseDown={handleMouseDown}
                    onMouseMove={handleMouseMove}
                    onMouseUp={handleMouseUp}
                    onMouseLeave={handleMouseUp} // é¼ æ ‡ç¦»å¼€æŒ‰é’®åŒºåŸŸæ—¶ä¹Ÿåœæ­¢å½•éŸ³
                    className={`mic-button ${isRecording ? 'recording' : ''} ${isButtonTouched ? 'touched' : ''}`}
                    style={{
                      width: '48px',
                      height: '48px',
                      borderRadius: '12px',
                      border: 'none',
                      backgroundColor: isRecording ? 'var(--error-color, #ef4444)' : 'var(--warning-color, #f59e0b)',
                      color: 'white',
                      fontSize: '18px',
                      cursor: (isProcessing || isProcessingMultimodal) ? 'not-allowed' : 'pointer',
                      opacity: (isProcessing || isProcessingMultimodal) ? 0.6 : 1,
                      transition: 'all 0.2s ease',
                      display: 'flex',
                      alignItems: 'center',
                      justifyContent: 'center',
                      boxShadow: isRecording ? '0 4px 16px rgba(239, 68, 68, 0.4)' : '0 2px 8px rgba(0, 0, 0, 0.1)',
                      transform: isRecording ? 'scale(1.1)' : (isButtonTouched ? 'scale(1.05)' : 'scale(1)'),
                      userSelect: 'none',
                      WebkitUserSelect: 'none',
                      WebkitTouchCallout: 'none',
                      position: 'relative',
                      overflow: 'hidden'
                    }}
                    title={isRecording ? 'æ¾å¼€åœæ­¢å½•éŸ³ï¼Œå‘ä¸Šæ»‘åŠ¨å–æ¶ˆ' : 'é•¿æŒ‰å¼€å§‹è¯­éŸ³è®°è´¦'}
                  >
                    {/* èƒŒæ™¯å‘¼å¸æ•ˆæœ */}
                    {isRecording && (
                      <div
                        className="breathing-effect"
                        style={{
                          position: 'absolute',
                          top: '50%',
                          left: '50%',
                          transform: 'translate(-50%, -50%)',
                          width: '100%',
                          height: '100%',
                          borderRadius: '12px',
                          background: 'radial-gradient(circle, rgba(255,255,255,0.2) 0%, rgba(255,255,255,0.1) 50%, transparent 70%)',
                          animation: 'breathe 2s ease-in-out infinite'
                        }}
                      />
                    )}
                    
                    {/* éŸ³é¢‘å¯è§†åŒ– */}
                    {isRecording && (
                      <div
                        className="audio-visualizer"
                        style={{
                          position: 'absolute',
                          bottom: '2px',
                          left: '50%',
                          transform: 'translateX(-50%)',
                          width: '80%',
                          height: '4px',
                          backgroundColor: 'rgba(255,255,255,0.3)',
                          borderRadius: '2px',
                          overflow: 'hidden'
                        }}
                      >
                        <div
                          style={{
                            width: `${Math.max(5, audioLevel)}%`,
                            height: '100%',
                            backgroundColor: 'white',
                            borderRadius: '2px',
                            transition: 'width 0.1s ease'
                          }}
                        />
                      </div>
                    )}
                    
                    {/* å›¾æ ‡ */}
                    <div style={{ position: 'relative', zIndex: 1 }}>
                      {isProcessingMultimodal ? (
                        <i className="fas fa-spinner fa-spin"></i>
                      ) : isRecording ? (
                        <i className="fas fa-stop"></i>
                      ) : (
                        <i className="fas fa-microphone"></i>
                      )}
                    </div>
                  </button>
                </div>
              </div>
            </div>
          </>
        )}
      </div>
    </div>
  );
}
