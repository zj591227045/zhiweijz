/**
 * æµè§ˆå™¨ç«¯éŸ³é¢‘æ ¼å¼è½¬æ¢å·¥å…·
 * å°†webmæ ¼å¼è½¬æ¢ä¸ºwavæ ¼å¼ï¼Œé¿å…åç«¯å¤„ç†
 */

export interface AudioConversionResult {
  blob: Blob;
  format: string;
  duration: number;
  size: number;
}

/**
 * æ£€æµ‹æµè§ˆå™¨æ”¯æŒçš„å½•éŸ³æ ¼å¼å¹¶é€‰æ‹©æœ€ä½³æ ¼å¼
 */
export function getBestAudioFormat(): string {
  const supportedTypes = [
    'audio/wav',
    'audio/mp4',
    'audio/mp3',
    'audio/webm;codecs=opus',
    'audio/webm'
  ];

  for (const type of supportedTypes) {
    if (MediaRecorder.isTypeSupported(type)) {
      console.log('ğŸ¤ [AudioFormat] æ”¯æŒçš„æ ¼å¼:', type);
      if (type.startsWith('audio/wav') || type.startsWith('audio/mp4') || type.startsWith('audio/mp3')) {
        return type; // ä¼˜å…ˆä½¿ç”¨å…¼å®¹æ€§æ›´å¥½çš„æ ¼å¼
      }
    }
  }

  // å¦‚æœéƒ½ä¸æ”¯æŒï¼Œå›é€€åˆ°webm
  return 'audio/webm';
}

/**
 * å°†AudioBufferè½¬æ¢ä¸ºWAVæ ¼å¼çš„ArrayBuffer
 */
function audioBufferToWav(buffer: AudioBuffer): ArrayBuffer {
  const numberOfChannels = Math.min(buffer.numberOfChannels, 2); // æœ€å¤šæ”¯æŒç«‹ä½“å£°
  const length = buffer.length;
  const sampleRate = buffer.sampleRate;
  const bytesPerSample = 2; // 16-bit
  
  // è®¡ç®—æ–‡ä»¶å¤§å°
  const headerLength = 44;
  const dataLength = length * numberOfChannels * bytesPerSample;
  const bufferLength = headerLength + dataLength;
  
  const arrayBuffer = new ArrayBuffer(bufferLength);
  const view = new DataView(arrayBuffer);
  
  // å†™å…¥å­—ç¬¦ä¸²è¾…åŠ©å‡½æ•°
  const writeString = (offset: number, string: string) => {
    for (let i = 0; i < string.length; i++) {
      view.setUint8(offset + i, string.charCodeAt(i));
    }
  };
  
  // WAVæ–‡ä»¶å¤´
  writeString(0, 'RIFF');
  view.setUint32(4, bufferLength - 8, true); // æ–‡ä»¶å¤§å°
  writeString(8, 'WAVE');
  writeString(12, 'fmt ');
  view.setUint32(16, 16, true); // PCMæ ¼å¼å—å¤§å°
  view.setUint16(20, 1, true); // PCMæ ¼å¼
  view.setUint16(22, numberOfChannels, true); // å£°é“æ•°
  view.setUint32(24, sampleRate, true); // é‡‡æ ·ç‡
  view.setUint32(28, sampleRate * numberOfChannels * bytesPerSample, true); // å­—èŠ‚ç‡
  view.setUint16(32, numberOfChannels * bytesPerSample, true); // å—å¯¹é½
  view.setUint16(34, 16, true); // é‡‡æ ·ä½æ•°
  writeString(36, 'data');
  view.setUint32(40, dataLength, true); // æ•°æ®å¤§å°
  
  // å†™å…¥éŸ³é¢‘æ•°æ®
  let offset = 44;
  for (let i = 0; i < length; i++) {
    for (let channel = 0; channel < numberOfChannels; channel++) {
      // è·å–éŸ³é¢‘æ ·æœ¬å¹¶è½¬æ¢ä¸º16ä½æ•´æ•°
      const channelData = buffer.getChannelData(channel);
      const sample = Math.max(-1, Math.min(1, channelData[i])); // é™åˆ¶èŒƒå›´
      view.setInt16(offset, sample * 0x7FFF, true); // è½¬æ¢ä¸º16ä½
      offset += 2;
    }
  }
  
  return arrayBuffer;
}

/**
 * å°†éŸ³é¢‘è½¬æ¢ä¸ºwavæ ¼å¼ï¼ˆæ”¯æŒwebmã€m4aç­‰æ ¼å¼ï¼‰
 */
export async function convertAudioToWav(audioBlob: Blob): Promise<AudioConversionResult> {
  const startTime = Date.now();
  const format = detectAudioFormat(audioBlob);
  
  try {
    console.log('ğŸ¤ [AudioConversion] å¼€å§‹è½¬æ¢éŸ³é¢‘åˆ°wavï¼ŒåŸæ ¼å¼:', format, 'æ–‡ä»¶å¤§å°:', audioBlob.size);
    
    // åˆ›å»ºAudioContext
    const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)({
      sampleRate: 16000 // è®¾ç½®ä¸º16kHzï¼Œé€‚åˆè¯­éŸ³è¯†åˆ«
    });
    
    // è¯»å–éŸ³é¢‘æ•°æ®
    const arrayBuffer = await audioBlob.arrayBuffer();
    console.log('ğŸ¤ [AudioConversion] è¯»å–éŸ³é¢‘æ•°æ®å®Œæˆï¼Œå¤§å°:', arrayBuffer.byteLength);
    
    // è§£ç éŸ³é¢‘æ•°æ®
    const audioBuffer = await audioContext.decodeAudioData(arrayBuffer.slice(0));
    console.log('ğŸ¤ [AudioConversion] éŸ³é¢‘è§£ç å®Œæˆ:', {
      duration: audioBuffer.duration,
      sampleRate: audioBuffer.sampleRate,
      channels: audioBuffer.numberOfChannels,
      length: audioBuffer.length
    });
    
    // å¦‚æœéœ€è¦ï¼Œé‡æ–°é‡‡æ ·åˆ°16kHzå•å£°é“
    let processedBuffer = audioBuffer;
    if (audioBuffer.sampleRate !== 16000 || audioBuffer.numberOfChannels !== 1) {
      console.log('ğŸ¤ [AudioConversion] éœ€è¦é‡æ–°é‡‡æ ·/è½¬æ¢å£°é“');
      processedBuffer = await resampleAudioBuffer(audioContext, audioBuffer, 16000, 1);
    }
    
    // è½¬æ¢ä¸ºWAVæ ¼å¼
    const wavArrayBuffer = audioBufferToWav(processedBuffer);
    const wavBlob = new Blob([wavArrayBuffer], { type: 'audio/wav' });
    
    // å…³é—­AudioContextä»¥é‡Šæ”¾èµ„æº
    await audioContext.close();
    
    const duration = Date.now() - startTime;
    const result: AudioConversionResult = {
      blob: wavBlob,
      format: 'wav',
      duration,
      size: wavBlob.size
    };
    
    console.log('ğŸ¤ [AudioConversion] è½¬æ¢å®Œæˆ:', {
      originalFormat: format,
      originalSize: audioBlob.size,
      convertedSize: wavBlob.size,
      duration: `${duration}ms`,
      sizeChange: `${((wavBlob.size - audioBlob.size) / audioBlob.size * 100).toFixed(1)}%`
    });
    
    return result;
    
  } catch (error) {
    console.error('ğŸ¤ [AudioConversion] è½¬æ¢å¤±è´¥:', error);
    throw new Error(`éŸ³é¢‘æ ¼å¼è½¬æ¢å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
  }
}

/**
 * é‡æ–°é‡‡æ ·AudioBufferåˆ°æŒ‡å®šé‡‡æ ·ç‡å’Œå£°é“æ•°
 */
async function resampleAudioBuffer(
  audioContext: AudioContext, 
  audioBuffer: AudioBuffer, 
  targetSampleRate: number, 
  targetChannels: number
): Promise<AudioBuffer> {
  // åˆ›å»ºç¦»çº¿éŸ³é¢‘ä¸Šä¸‹æ–‡è¿›è¡Œé‡é‡‡æ ·
  const offlineContext = new OfflineAudioContext(
    targetChannels, 
    Math.ceil(audioBuffer.duration * targetSampleRate), 
    targetSampleRate
  );
  
  // åˆ›å»ºéŸ³é¢‘æº
  const source = offlineContext.createBufferSource();
  source.buffer = audioBuffer;
  
  // å¦‚æœéœ€è¦è½¬æ¢å£°é“æ•°ï¼Œæ·»åŠ å£°é“åˆå¹¶å™¨
  if (audioBuffer.numberOfChannels !== targetChannels) {
    const merger = offlineContext.createChannelMerger(targetChannels);
    const splitter = offlineContext.createChannelSplitter(audioBuffer.numberOfChannels);
    
    source.connect(splitter);
    
    // å¦‚æœæ˜¯ç«‹ä½“å£°è½¬å•å£°é“ï¼Œåˆå¹¶å·¦å³å£°é“
    if (audioBuffer.numberOfChannels > 1 && targetChannels === 1) {
      const gainNode = offlineContext.createGain();
      gainNode.gain.value = 1 / audioBuffer.numberOfChannels; // å¹³å‡éŸ³é‡
      
      for (let i = 0; i < Math.min(audioBuffer.numberOfChannels, 2); i++) {
        splitter.connect(gainNode, i);
      }
      gainNode.connect(merger, 0, 0);
    } else {
      // ç®€å•è¿æ¥ç¬¬ä¸€ä¸ªå£°é“
      splitter.connect(merger, 0, 0);
    }
    
    merger.connect(offlineContext.destination);
  } else {
    source.connect(offlineContext.destination);
  }
  
  source.start(0);
  
  return await offlineContext.startRendering();
}

/**
 * æ£€æµ‹éŸ³é¢‘æ ¼å¼
 */
export function detectAudioFormat(blob: Blob): string {
  const type = blob.type.toLowerCase();
  
  if (type.includes('wav')) return 'wav';
  if (type.includes('mp3')) return 'mp3';
  if (type.includes('mp4') || type.includes('m4a')) return 'm4a';
  if (type.includes('flac')) return 'flac';
  if (type.includes('aac')) return 'aac';
  if (type.includes('webm')) return 'webm';
  
  return 'unknown';
}

/**
 * æ£€æŸ¥æ ¼å¼æ˜¯å¦éœ€è¦è½¬æ¢ï¼ˆåŸºäºç™¾åº¦äº‘æ”¯æŒçš„æ ¼å¼ï¼‰
 */
export function needsConversion(format: string): boolean {
  // ç™¾åº¦äº‘å®é™…ç¨³å®šæ”¯æŒçš„æ ¼å¼æ¯”è¾ƒæœ‰é™ï¼Œå»ºè®®è½¬æ¢æ›´å¤šæ ¼å¼ä¸ºwav
  const stableSupportedFormats = ['wav', 'mp3'];
  return !stableSupportedFormats.includes(format);
}

/**
 * æ™ºèƒ½éŸ³é¢‘å¤„ç†ï¼šè‡ªåŠ¨æ£€æµ‹æ ¼å¼å¹¶è½¬æ¢
 */
export async function processAudioForSpeechRecognition(audioBlob: Blob): Promise<AudioConversionResult> {
  const format = detectAudioFormat(audioBlob);
  console.log('ğŸ¤ [AudioProcess] æ£€æµ‹åˆ°éŸ³é¢‘æ ¼å¼:', format);
  
  if (!needsConversion(format)) {
    // æ ¼å¼å·²ç»æ”¯æŒï¼Œç›´æ¥è¿”å›
    return {
      blob: audioBlob,
      format,
      duration: 0,
      size: audioBlob.size
    };
  }
  
  // éœ€è¦è½¬æ¢ï¼Œç»Ÿä¸€è½¬æ¢ä¸ºwavæ ¼å¼
  console.log('ğŸ¤ [AudioProcess] éœ€è¦è½¬æ¢æ ¼å¼:', format, 'â†’ wav');
  return await convertAudioToWav(audioBlob);
}