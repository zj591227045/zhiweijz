import { LLMProvider } from './llm-provider';
import { OpenAIProvider } from './openai-provider';
import { SiliconFlowProvider } from './siliconflow-provider';
import { DeepseekProvider } from './deepseek-provider';
import { CustomProvider } from './custom-provider';
import { LLMSettings, Message, LLMResponse } from '../types/llm-types';
import { TokenLimitService } from '../../services/token-limit.service';
import prisma from '../../config/database';

/**
 * LLMæä¾›å•†æœåŠ¡
 * ç®¡ç†å¤šä¸ªLLMæä¾›å•†ï¼Œæä¾›ç»Ÿä¸€çš„æ¥å£
 */
export class LLMProviderService {
  /** æä¾›å•†æ˜ å°„ */
  private providers: Map<string, LLMProvider> = new Map();
  /** Tokené™åˆ¶æœåŠ¡ */
  private tokenLimitService: TokenLimitService = new TokenLimitService();
  /** é»˜è®¤è®¾ç½® */
  private defaultSettings: LLMSettings = {
    provider: 'siliconflow',
    apiKey: process.env.SILICONFLOW_API_KEY || '',
    model: 'Qwen/Qwen3-32B',
    temperature: 0.7,
    maxTokens: 1000,
  };
  /**
   * ç®€å•çš„tokenä¼°ç®—æ–¹æ³•ï¼ˆä½œä¸ºå›é€€ï¼‰
   * @param text æ–‡æœ¬å†…å®¹
   * @returns ä¼°ç®—çš„tokenæ•°é‡
   */
  private estimateTokens(text: string): number {
    // ç®€å•ä¼°ç®—ï¼šä¸­æ–‡å­—ç¬¦æŒ‰1.5ä¸ªå­—ç¬¦=1tokenè®¡ç®—ï¼Œå…¶ä»–æŒ‰4ä¸ªå­—ç¬¦=1token
    const chineseCharCount = (text.match(/[\u4e00-\u9fff]/g) || []).length;
    const otherCharCount = text.length - chineseCharCount;
    return Math.ceil(chineseCharCount / 1.5 + otherCharCount / 4);
  }

  /**
   * æ„é€ å‡½æ•°
   * æ³¨å†Œé»˜è®¤æä¾›å•†
   */
  constructor() {

    // æ³¨å†ŒOpenAIæä¾›å•†
    this.registerProvider(new OpenAIProvider());

    // æ³¨å†Œç¡…åŸºæµåŠ¨æä¾›å•†
    this.registerProvider(new SiliconFlowProvider());

    // æ³¨å†ŒDeepseekæä¾›å•†
    this.registerProvider(new DeepseekProvider());

    // æ³¨å†Œè‡ªå®šä¹‰æä¾›å•†
    this.registerProvider(new CustomProvider());
  }

  /**
   * æ³¨å†ŒLLMæä¾›å•†
   * @param provider LLMæä¾›å•†
   */
  public registerProvider(provider: LLMProvider): void {
    this.providers.set(provider.name, provider);
  }

  /**
   * è·å–LLMæä¾›å•†
   * @param providerName æä¾›å•†åç§°
   * @returns LLMæä¾›å•†
   */
  public getProvider(providerName: string): LLMProvider {
    const provider = this.providers.get(providerName);
    if (!provider) {
      throw new Error(`LLM provider '${providerName}' not found`);
    }
    return provider;
  }

  /**
   * è·å–æ‰€æœ‰æ³¨å†Œçš„æä¾›å•†åç§°
   * @returns æä¾›å•†åç§°é›†åˆ
   */
  public getProviderNames(): Set<string> {
    return new Set(this.providers.keys());
  }

  /**
   * è·å–ç”¨æˆ·æˆ–è´¦æœ¬çš„LLMè®¾ç½®
   * @param userId ç”¨æˆ·ID
   * @param accountId è´¦æœ¬ID (å¯é€‰)
   * @param accountType è´¦æœ¬ç±»å‹ (å¯é€‰)
   * @returns LLMè®¾ç½®
   */
  public async getLLMSettings(
    userId: string,
    accountId?: string,
    accountType?: 'personal' | 'family'
  ): Promise<LLMSettings> {
    try {
      // é¦–å…ˆæ£€æŸ¥ç³»ç»Ÿé…ç½®ä¸­çš„AIæœåŠ¡ç±»å‹
      const serviceTypeConfig = await prisma.systemConfig.findUnique({
        where: { key: 'llm_service_type' }
      });

      const serviceType = serviceTypeConfig?.value || 'official';
      console.log(`å½“å‰AIæœåŠ¡ç±»å‹: ${serviceType}`);

      // å¦‚æœæ˜¯å®˜æ–¹AIæœåŠ¡ï¼Œä½¿ç”¨å…¨å±€é…ç½®
      if (serviceType === 'official') {
        console.log('ä½¿ç”¨å®˜æ–¹AIæœåŠ¡é…ç½®');
        const globalConfig = await this.getFullGlobalLLMConfig();
        
        if (globalConfig) {
          console.log(`ä½¿ç”¨å…¨å±€LLMé…ç½®: ${globalConfig.provider}/${globalConfig.model}`);
          return globalConfig;
        }
      }

      // å¦‚æœæ˜¯è‡ªå®šä¹‰AIæœåŠ¡ï¼ŒæŒ‰åŸæœ‰é€»è¾‘æŸ¥æ‰¾ç”¨æˆ·/è´¦æœ¬è®¾ç½®
      if (serviceType === 'custom') {
        console.log('ä½¿ç”¨è‡ªå®šä¹‰AIæœåŠ¡é…ç½®');
        
        // å¦‚æœæä¾›äº†è´¦æœ¬ä¿¡æ¯ï¼Œä¼˜å…ˆä½¿ç”¨è´¦æœ¬ç»‘å®šçš„UserLLMSetting
        if (accountId) {
          try {
            // æŸ¥æ‰¾è´¦æœ¬
            const accountBook = await prisma.accountBook.findUnique({
              where: { id: accountId }
            });

            // å¦‚æœè´¦æœ¬å­˜åœ¨
            if (accountBook) {
              // æŸ¥æ‰¾å…³è”çš„UserLLMSetting
              const userLLMSettings = await prisma.$queryRaw`
                SELECT u.* FROM "user_llm_settings" u
                JOIN "account_books" a ON a."user_llm_setting_id" = u.id
                WHERE a.id = ${accountId}
              `;

              // ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„è®¾ç½®
              const userLLMSetting = Array.isArray(userLLMSettings) && userLLMSettings.length > 0 ? userLLMSettings[0] : null;

              if (userLLMSetting) {
                console.log(`è´¦æœ¬ ${accountId} ä½¿ç”¨ç»‘å®šçš„LLMè®¾ç½®: ${userLLMSetting.id}`);
                return {
                  provider: userLLMSetting.provider || this.defaultSettings.provider,
                  model: userLLMSetting.model || this.defaultSettings.model,
                  apiKey: userLLMSetting.api_key || process.env[`${(userLLMSetting.provider || this.defaultSettings.provider).toUpperCase()}_API_KEY`] || '',
                  temperature: userLLMSetting.temperature || this.defaultSettings.temperature,
                  maxTokens: userLLMSetting.max_tokens || this.defaultSettings.maxTokens,
                  baseUrl: userLLMSetting.base_url
                };
              }
            }

            // å¦‚æœè´¦æœ¬æ²¡æœ‰ç»‘å®šUserLLMSettingï¼Œå°è¯•ä½¿ç”¨æ—§çš„AccountLLMSetting
            const accountSettings = await prisma.accountLLMSetting.findFirst({
              where: { accountBookId: accountId }
            });

            if (accountSettings) {
              console.log(`è´¦æœ¬ ${accountId} ä½¿ç”¨æ—§çš„AccountLLMSetting`);
              return {
                provider: accountSettings.provider,
                model: accountSettings.model,
                apiKey: accountSettings.apiKey || process.env[`${accountSettings.provider.toUpperCase()}_API_KEY`] || '',
                temperature: accountSettings.temperature,
                maxTokens: accountSettings.maxTokens
              };
            }
          } catch (error) {
            console.error('è·å–è´¦æœ¬LLMè®¾ç½®é”™è¯¯:', error);
          }
        }

        // å¦‚æœæ²¡æœ‰è´¦æœ¬è®¾ç½®æˆ–æœªæä¾›è´¦æœ¬ä¿¡æ¯ï¼Œä½¿ç”¨ç”¨æˆ·çš„é»˜è®¤LLMè®¾ç½®
        try {
          // æŸ¥æ‰¾ç”¨æˆ·çš„é»˜è®¤LLMè®¾ç½®
          const userLLMSettings = await prisma.$queryRaw`
            SELECT * FROM "user_llm_settings"
            WHERE "user_id" = ${userId}
            LIMIT 1
          `;

          const userLLMSetting = Array.isArray(userLLMSettings) && userLLMSettings.length > 0 ? userLLMSettings[0] : null;

          if (userLLMSetting) {
            console.log(`ç”¨æˆ· ${userId} ä½¿ç”¨UserLLMSetting: ${userLLMSetting.id}`);
            return {
              provider: userLLMSetting.provider || this.defaultSettings.provider,
              model: userLLMSetting.model || this.defaultSettings.model,
              apiKey: userLLMSetting.api_key || process.env[`${(userLLMSetting.provider || this.defaultSettings.provider).toUpperCase()}_API_KEY`] || '',
              temperature: userLLMSetting.temperature || this.defaultSettings.temperature,
              maxTokens: userLLMSetting.max_tokens || this.defaultSettings.maxTokens,
              baseUrl: userLLMSetting.base_url
            };
          }

          // å¦‚æœæ²¡æœ‰æ‰¾åˆ°UserLLMSettingï¼Œå°è¯•ä»userSettingè¡¨è·å–
          const userSettings = await prisma.userSetting.findFirst({
            where: {
              userId,
              key: 'llm_settings'
            }
          });

          if (userSettings && userSettings.value) {
            try {
              console.log(`ç”¨æˆ· ${userId} ä½¿ç”¨UserSettingä¸­çš„llm_settings`);
              const llmSettings = JSON.parse(userSettings.value);
              return {
                provider: llmSettings.provider || this.defaultSettings.provider,
                model: llmSettings.model || this.defaultSettings.model,
                apiKey: llmSettings.apiKey || process.env[`${llmSettings.provider.toUpperCase()}_API_KEY`] || '',
                temperature: llmSettings.temperature || this.defaultSettings.temperature,
                maxTokens: llmSettings.maxTokens || this.defaultSettings.maxTokens,
                baseUrl: llmSettings.baseUrl
              };
            } catch (parseError) {
              console.error('è§£æç”¨æˆ·LLMè®¾ç½®é”™è¯¯:', parseError);
            }
          }
        } catch (error) {
          console.error('è·å–ç”¨æˆ·LLMè®¾ç½®é”™è¯¯:', error);
        }
      }

      // å›é€€åˆ°å…¨å±€é…ç½®
      console.log(`å›é€€åˆ°å…¨å±€LLMé…ç½®`);
      const globalConfig = await this.getFullGlobalLLMConfig();
      
      if (globalConfig) {
        console.log(`ä½¿ç”¨å…¨å±€LLMé…ç½®: ${globalConfig.provider}/${globalConfig.model}`);
        return globalConfig;
      }

      // å¦‚æœæ²¡æœ‰å…¨å±€é…ç½®ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®
      console.log(`ä½¿ç”¨é»˜è®¤LLMè®¾ç½®`);
      return {
        ...this.defaultSettings,
        apiKey: process.env.SILICONFLOW_API_KEY || ''
      };
    } catch (error) {
      console.error('è·å–LLMè®¾ç½®é”™è¯¯:', error);
      
      // å³ä½¿å‡ºé”™ï¼Œä¹Ÿå°è¯•ä½¿ç”¨å…¨å±€é…ç½®
      try {
        const globalConfig = await this.getFullGlobalLLMConfig();
        if (globalConfig) {
          console.log(`å›é€€åˆ°å…¨å±€LLMé…ç½®: ${globalConfig.provider}/${globalConfig.model}`);
          return globalConfig;
        }
      } catch (globalError) {
        console.error('è·å–å…¨å±€LLMé…ç½®é”™è¯¯:', globalError);
      }
      
      return {
        ...this.defaultSettings,
        apiKey: process.env.SILICONFLOW_API_KEY || ''
      };
    }
  }

  /**
   * æ›´æ–°ç”¨æˆ·LLMè®¾ç½®
   * @param userId ç”¨æˆ·ID
   * @param settings LLMè®¾ç½®
   */
  public async updateUserLLMSettings(userId: string, settings: Partial<LLMSettings>): Promise<void> {
    try {
      // ç”±äºuserLLMSettingè¡¨å¯èƒ½è¿˜ä¸å­˜åœ¨ï¼Œæˆ‘ä»¬ä½¿ç”¨userSettingè¡¨æ¥å­˜å‚¨LLMè®¾ç½®
      const existingSettings = await prisma.userSetting.findFirst({
        where: {
          userId,
          key: 'llm_settings'
        }
      });

      const llmSettings = {
        provider: settings.provider || this.defaultSettings.provider,
        model: settings.model || this.defaultSettings.model,
        apiKey: settings.apiKey,
        temperature: settings.temperature || this.defaultSettings.temperature,
        maxTokens: settings.maxTokens || this.defaultSettings.maxTokens
      };

      if (existingSettings) {
        // æ›´æ–°ç°æœ‰è®¾ç½®
        await prisma.userSetting.update({
          where: { id: existingSettings.id },
          data: {
            value: JSON.stringify(llmSettings)
          }
        });
      } else {
        // åˆ›å»ºæ–°è®¾ç½®
        await prisma.userSetting.create({
          data: {
            userId,
            key: 'llm_settings',
            value: JSON.stringify(llmSettings)
          }
        });
      }
    } catch (error) {
      console.error('æ›´æ–°ç”¨æˆ·LLMè®¾ç½®é”™è¯¯:', error);
      throw error;
    }
  }

  /**
   * æ›´æ–°è´¦æœ¬LLMè®¾ç½®
   * @param accountId è´¦æœ¬ID
   * @param userLLMSettingId ç”¨æˆ·LLMè®¾ç½®ID
   */
  public async updateAccountLLMSettings(
    accountId: string,
    userLLMSettingId: string
  ): Promise<void> {
    try {
      // æ£€æŸ¥è´¦æœ¬æ˜¯å¦å­˜åœ¨
      const accountBook = await prisma.accountBook.findUnique({
        where: { id: accountId }
      });

      if (!accountBook) {
        throw new Error(`è´¦æœ¬ä¸å­˜åœ¨: ${accountId}`);
      }

      // æ£€æŸ¥ç”¨æˆ·LLMè®¾ç½®æ˜¯å¦å­˜åœ¨
      const userLLMSettings = await prisma.$queryRaw`
        SELECT * FROM "user_llm_settings"
        WHERE "id" = ${userLLMSettingId}
      `;

      const userLLMSetting = Array.isArray(userLLMSettings) && userLLMSettings.length > 0 ? userLLMSettings[0] : null;

      if (!userLLMSetting) {
        throw new Error(`ç”¨æˆ·LLMè®¾ç½®ä¸å­˜åœ¨: ${userLLMSettingId}`);
      }

      // æ›´æ–°è´¦æœ¬çš„userLLMSettingId
      await prisma.$executeRaw`
        UPDATE "account_books"
        SET "user_llm_setting_id" = ${userLLMSettingId}
        WHERE "id" = ${accountId}
      `;

      console.log(`è´¦æœ¬ ${accountId} å·²ç»‘å®šåˆ°LLMè®¾ç½® ${userLLMSettingId}`);
    } catch (error) {
      console.error('æ›´æ–°è´¦æœ¬LLMè®¾ç½®é”™è¯¯:', error);
      throw error;
    }
  }

  /**
   * åˆ›å»ºç”¨æˆ·LLMè®¾ç½®
   * @param userId ç”¨æˆ·ID
   * @param settings LLMè®¾ç½®
   * @returns åˆ›å»ºçš„LLMè®¾ç½®ID
   */
  public async createUserLLMSetting(
    userId: string,
    settings: {
      name: string;
      provider: string;
      model: string;
      apiKey?: string;
      temperature?: number;
      maxTokens?: number;
      baseUrl?: string;
      description?: string;
    }
  ): Promise<string> {
    try {
      console.log('å¼€å§‹åˆ›å»ºç”¨æˆ·LLMè®¾ç½®:', { userId, settings });

      // ä½¿ç”¨Prisma ORMæ–¹æ³•åˆ›å»ºè®°å½•ï¼Œè¿™æ ·æ›´å®‰å…¨å¯é 
      const createdSetting = await prisma.userLLMSetting.create({
        data: {
          userId,
          name: settings.name,
          provider: settings.provider,
          model: settings.model,
          apiKey: settings.apiKey || null,
          temperature: settings.temperature || 0.7,
          maxTokens: settings.maxTokens || 1000,
          baseUrl: settings.baseUrl || null,
          description: settings.description || null,
        },
        select: {
          id: true
        }
      });

      console.log('æˆåŠŸåˆ›å»ºç”¨æˆ·LLMè®¾ç½®:', createdSetting.id);
      return createdSetting.id;
    } catch (error) {
      console.error('åˆ›å»ºç”¨æˆ·LLMè®¾ç½®é”™è¯¯:', error);
      throw error;
    }
  }

  /**
   * ç”Ÿæˆæ–‡æœ¬
   * @param prompt æç¤ºæ–‡æœ¬
   * @param userId ç”¨æˆ·ID
   * @param accountId è´¦æœ¬ID (å¯é€‰)
   * @param accountType è´¦æœ¬ç±»å‹ (å¯é€‰)
   * @returns ç”Ÿæˆçš„æ–‡æœ¬
   */
  public async generateText(
    prompt: string,
    userId: string,
    accountId?: string,
    accountType?: 'personal' | 'family'
  ): Promise<string> {
    // ğŸ’¡ Tokené™åˆ¶æ£€æŸ¥ - é¢„ä¼°promptçš„tokenæ•°é‡
    const estimatedPromptTokens = this.estimateTokens(prompt);
    const tokenCheck = await this.tokenLimitService.canUseTokens(userId, estimatedPromptTokens);
    
    if (!tokenCheck.canUse) {
      throw new Error(`Tokenä½¿ç”¨å—é™: ${tokenCheck.reason}`);
    }

    const settings = await this.getLLMSettings(userId, accountId, accountType);
    const provider = this.getProvider(settings.provider);
    
    // ç¡®å®šæœåŠ¡ç±»å‹
    const globalConfig = await this.getGlobalLLMConfig();
    const serviceType = globalConfig.enabled ? 'official' : 'custom';
    
    const startTime = Date.now();
    let result: string = '';
    let isSuccess = false;
    let errorMessage: string | null = null;
    let promptTokens = 0;
    let completionTokens = 0;

    try {
      // å°è¯•ä½¿ç”¨å¸¦tokenä½¿ç”¨é‡ä¿¡æ¯çš„æ–¹æ³•
      if (provider.generateTextWithUsage) {
        const response: LLMResponse = await provider.generateTextWithUsage(prompt, settings);
        result = response.content;
        
        if (response.usage) {
          promptTokens = response.usage.prompt_tokens;
          completionTokens = response.usage.completion_tokens;
        } else {
          // å¦‚æœAPIæ²¡æœ‰è¿”å›usageä¿¡æ¯ï¼Œå›é€€åˆ°ä¼°ç®—
          promptTokens = this.estimateTokens(prompt);
          completionTokens = this.estimateTokens(result);
        }
              } else {
          // å›é€€åˆ°åŸæ¥çš„æ–¹æ³•
          result = await provider.generateText(prompt, settings);
          promptTokens = this.estimateTokens(prompt);
          completionTokens = this.estimateTokens(result);
        }
      
      isSuccess = true;
      return result;
    } catch (error) {
      isSuccess = false;
      errorMessage = error instanceof Error ? error.message : String(error);
      throw error;
    } finally {
      const duration = Date.now() - startTime;
      await this.logLLMCall({
        userId,
        accountId,
        provider: settings.provider,
        model: settings.model,
        userMessage: prompt,
        assistantMessage: result || null,
        systemPrompt: null,
        isSuccess,
        errorMessage,
        duration,
        promptTokens,
        completionTokens,
        serviceType
      });
    }
  }

  /**
   * ç”ŸæˆèŠå¤©å“åº”
   * @param messages æ¶ˆæ¯æ•°ç»„
   * @param userId ç”¨æˆ·ID
   * @param accountId è´¦æœ¬ID (å¯é€‰)
   * @param accountType è´¦æœ¬ç±»å‹ (å¯é€‰)
   * @returns ç”Ÿæˆçš„å“åº”
   */
  public async generateChat(
    messages: Message[],
    userId: string,
    accountId?: string,
    accountType?: 'personal' | 'family'
  ): Promise<string> {
    // ğŸ’¡ Tokené™åˆ¶æ£€æŸ¥ - é¢„ä¼°æ‰€æœ‰æ¶ˆæ¯çš„tokenæ•°é‡
    const allMessagesText = messages.map(m => m.content).join('\n');
    const estimatedPromptTokens = this.estimateTokens(allMessagesText);
    const tokenCheck = await this.tokenLimitService.canUseTokens(userId, estimatedPromptTokens);
    
    if (!tokenCheck.canUse) {
      throw new Error(`Tokenä½¿ç”¨å—é™: ${tokenCheck.reason}`);
    }

    const settings = await this.getLLMSettings(userId, accountId, accountType);
    const provider = this.getProvider(settings.provider);
    
    // ç¡®å®šæœåŠ¡ç±»å‹
    const globalConfig = await this.getGlobalLLMConfig();
    const serviceType = globalConfig.enabled ? 'official' : 'custom';
    
    const startTime = Date.now();
    let result: string = '';
    let isSuccess = false;
    let errorMessage: string | null = null;
    let promptTokens = 0;
    let completionTokens = 0;

    // æå–ç³»ç»Ÿæ¶ˆæ¯å’Œç”¨æˆ·æ¶ˆæ¯
    const systemMessage = messages.find(m => m.role === 'system')?.content || null;
    const userMessage = messages.filter(m => m.role === 'user').map(m => m.content).join('\n');

    try {
      // å°è¯•ä½¿ç”¨å¸¦tokenä½¿ç”¨é‡ä¿¡æ¯çš„æ–¹æ³•
      if (provider.generateChatWithUsage) {
        const response: LLMResponse = await provider.generateChatWithUsage(messages, settings);
        result = response.content;
        
        if (response.usage) {
          promptTokens = response.usage.prompt_tokens;
          completionTokens = response.usage.completion_tokens;
        } else {
          // å¦‚æœAPIæ²¡æœ‰è¿”å›usageä¿¡æ¯ï¼Œå›é€€åˆ°ä¼°ç®—
          const promptText = (systemMessage || '') + userMessage;
          promptTokens = this.estimateTokens(promptText);
          completionTokens = this.estimateTokens(result);
        }
      } else {
        // å›é€€åˆ°åŸæ¥çš„æ–¹æ³•
        result = await provider.generateChat(messages, settings);
        const promptText = (systemMessage || '') + userMessage;
        promptTokens = this.estimateTokens(promptText);
        completionTokens = this.estimateTokens(result);
      }
      
      isSuccess = true;
      return result;
    } catch (error) {
      isSuccess = false;
      errorMessage = error instanceof Error ? error.message : String(error);
      throw error;
    } finally {
      const duration = Date.now() - startTime;
      
      await this.logLLMCall({
        userId,
        accountId,
        provider: settings.provider,
        model: settings.model,
        userMessage,
        assistantMessage: result || null,
        systemPrompt: systemMessage,
        isSuccess,
        errorMessage,
        duration,
        promptTokens,
        completionTokens,
        serviceType
      });
    }
  }

  /**
   * æµ‹è¯•LLMè¿æ¥
   * @param settings æµ‹è¯•ç”¨çš„LLMè®¾ç½®
   * @returns æµ‹è¯•ç»“æœ
   */
  public async testConnection(settings: {
    provider: string;
    model: string;
    apiKey: string;
    baseUrl?: string;
  }): Promise<{ success: boolean; message: string }> {
    try {
      // æ£€æŸ¥æä¾›å•†æ˜¯å¦å­˜åœ¨
      if (!this.providers.has(settings.provider)) {
        return {
          success: false,
          message: `æœªçŸ¥çš„æä¾›å•†: ${settings.provider}`
        };
      }

      // æ£€æŸ¥APIå¯†é’¥
      if (!settings.apiKey) {
        return {
          success: false,
          message: 'APIå¯†é’¥ä¸èƒ½ä¸ºç©º'
        };
      }

      // è·å–æä¾›å•†
      const provider = this.getProvider(settings.provider);

      // æ„å»ºå®Œæ•´çš„è®¾ç½®
      const fullSettings = {
        provider: settings.provider,
        model: settings.model,
        apiKey: settings.apiKey,
        baseUrl: settings.baseUrl,
        temperature: 0.7,
        maxTokens: 100
      };

      // å°è¯•å‘é€ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯·æ±‚
      try {
        // ä½¿ç”¨ä¸€ä¸ªç®€å•çš„æç¤ºè¿›è¡Œæµ‹è¯•
        const testPrompt = "Hello, this is a test message. Please respond with 'OK' if you receive this.";
        const response = await provider.generateText(testPrompt, fullSettings);

        return {
          success: true,
          message: `è¿æ¥æµ‹è¯•æˆåŠŸ: ${response.substring(0, 50)}${response.length > 50 ? '...' : ''}`
        };
      } catch (apiError) {
        console.error('APIè°ƒç”¨é”™è¯¯:', apiError);
        return {
          success: false,
          message: `è¿æ¥æµ‹è¯•å¤±è´¥: ${apiError instanceof Error ? apiError.message : String(apiError)}`
        };
      }
    } catch (error) {
      console.error('æµ‹è¯•è¿æ¥é”™è¯¯:', error);
      return {
        success: false,
        message: `æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: ${error instanceof Error ? error.message : String(error)}`
      };
    }
  }

  /**
   * è·å–å…¨å±€LLMé…ç½®
   * @returns å…¨å±€LLMé…ç½®ï¼ˆä¸åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼‰
   */
  public async getGlobalLLMConfig(): Promise<{
    enabled: boolean;
    provider?: string;
    model?: string;
    baseUrl?: string;
    temperature?: number;
    maxTokens?: number;
  }> {
    try {
      const llmConfigs = await prisma.systemConfig.findMany({
        where: {
          category: 'llm'
        }
      });

      // è½¬æ¢ä¸ºå¯¹è±¡æ ¼å¼
      const configObj: any = { enabled: false };
      
      llmConfigs.forEach(config => {
        const key = config.key.replace('llm_global_', '');
        if (key === 'enabled') {
          configObj[key] = config.value === 'true';
        } else if (key === 'temperature') {
          configObj[key] = parseFloat(config.value || '0.7');
        } else if (key === 'max_tokens') {
          configObj['maxTokens'] = parseInt(config.value || '1000');
        } else if (key !== 'api_key') { // æ’é™¤æ•æ„Ÿä¿¡æ¯
          configObj[key] = config.value;
        }
      });

      return configObj;
    } catch (error) {
      console.error('è·å–å…¨å±€LLMé…ç½®é”™è¯¯:', error);
      return { enabled: false };
    }
  }

  /**
   * è·å–å…¨å±€LLMé…ç½®ï¼ˆåŒ…å«API Keyï¼Œä»…ä¾›å†…éƒ¨ä½¿ç”¨ï¼‰
   * @returns å®Œæ•´çš„å…¨å±€LLMé…ç½®
   */
  private async getFullGlobalLLMConfig(): Promise<LLMSettings | null> {
    try {
      const llmConfigs = await prisma.systemConfig.findMany({
        where: {
          category: 'llm'
        }
      });

      // è½¬æ¢ä¸ºå¯¹è±¡æ ¼å¼
      const configObj: any = {};
      
      llmConfigs.forEach(config => {
        const key = config.key.replace('llm_global_', '');
        if (key === 'enabled') {
          configObj[key] = config.value === 'true';
        } else if (key === 'temperature') {
          configObj[key] = parseFloat(config.value || '0.7');
        } else if (key === 'max_tokens') {
          configObj['maxTokens'] = parseInt(config.value || '1000');
        } else if (key === 'api_key') {
          configObj['apiKey'] = config.value;
        } else if (key === 'base_url') {
          configObj['baseUrl'] = config.value;
        } else {
          configObj[key] = config.value;
        }
      });

      // æ£€æŸ¥æ˜¯å¦å¯ç”¨ä¸”é…ç½®å®Œæ•´
      if (configObj.enabled && configObj.provider && configObj.model) {
        return {
          provider: configObj.provider,
          model: configObj.model,
          apiKey: configObj.apiKey || '',
          temperature: configObj.temperature || this.defaultSettings.temperature,
          maxTokens: configObj.maxTokens || this.defaultSettings.maxTokens,
          baseUrl: configObj.baseUrl
        };
      }

      return null;
    } catch (error) {
      console.error('è·å–å®Œæ•´å…¨å±€LLMé…ç½®é”™è¯¯:', error);
      return null;
    }
  }

  /**
   * è®°å½•LLMè°ƒç”¨æ—¥å¿—
   * @param logData æ—¥å¿—æ•°æ®
   */
  private async logLLMCall(logData: {
    userId: string;
    accountId?: string;
    provider: string;
    model: string;
    userMessage: string;
    assistantMessage: string | null;
    systemPrompt: string | null;
    isSuccess: boolean;
    errorMessage: string | null;
    duration: number;
    promptTokens: number;
    completionTokens: number;
    serviceType?: string;
  }): Promise<void> {
    try {
      // è·å–ç”¨æˆ·ä¿¡æ¯
      const user = await prisma.user.findUnique({
        where: { id: logData.userId },
        select: { name: true }
      });

      // è·å–è´¦æœ¬ä¿¡æ¯ï¼ˆå¦‚æœæä¾›äº†accountIdï¼‰
      let accountBook = null;
      if (logData.accountId) {
        accountBook = await prisma.accountBook.findUnique({
          where: { id: logData.accountId },
          select: { name: true }
        });
      }

      // è®¡ç®—æ€»tokenæ•°
      const totalTokens = logData.promptTokens + logData.completionTokens;

      // è®¡ç®—æˆæœ¬ï¼ˆè¿™é‡Œå¯ä»¥æ ¹æ®ä¸åŒæä¾›å•†çš„å®šä»·æ¨¡å‹æ¥è®¡ç®—ï¼‰
      const cost = this.calculateCost(logData.provider, logData.model, logData.promptTokens, logData.completionTokens);

      // ç¡®å®šæœåŠ¡ç±»å‹ï¼šå¦‚æœæ²¡æœ‰æ˜ç¡®æŒ‡å®šï¼Œåˆ™æ ¹æ®å½“å‰LLMè®¾ç½®æ¥åˆ¤æ–­
      let serviceType = logData.serviceType;
      if (!serviceType) {
        // æ£€æŸ¥æ˜¯å¦ä½¿ç”¨å…¨å±€é…ç½®
        const globalConfig = await this.getGlobalLLMConfig();
        if (globalConfig.enabled) {
          serviceType = 'official';
        } else {
          serviceType = 'custom';
        }
      }

      // åˆ›å»ºæ—¥å¿—è®°å½•
      await prisma.llmCallLog.create({
        data: {
          userId: logData.userId,
          userName: user?.name || 'Unknown User',
          accountBookId: logData.accountId || null,
          accountBookName: accountBook?.name || null,
          provider: logData.provider,
          model: logData.model,
          serviceType: serviceType,
          promptTokens: logData.promptTokens,
          completionTokens: logData.completionTokens,
          totalTokens: totalTokens,
          userMessage: logData.userMessage,
          assistantMessage: logData.assistantMessage,
          systemPrompt: logData.systemPrompt,
          isSuccess: logData.isSuccess,
          errorMessage: logData.errorMessage,
          duration: logData.duration,
          cost: cost
        }
      });

      console.log(`LLMè°ƒç”¨æ—¥å¿—å·²è®°å½•: ${logData.provider}/${logData.model}, tokens: ${totalTokens}, duration: ${logData.duration}ms, serviceType: ${serviceType}`);
    } catch (error) {
      console.error('è®°å½•LLMè°ƒç”¨æ—¥å¿—å¤±è´¥:', error);
      // ä¸æŠ›å‡ºé”™è¯¯ï¼Œé¿å…å½±å“ä¸»è¦åŠŸèƒ½
    }
  }

  /**
   * è®¡ç®—LLMè°ƒç”¨æˆæœ¬
   * @param provider æä¾›å•†
   * @param model æ¨¡å‹
   * @param promptTokens è¾“å…¥tokenæ•°é‡
   * @param completionTokens è¾“å‡ºtokenæ•°é‡
   * @returns æˆæœ¬ï¼ˆç¾å…ƒï¼‰
   */
  private calculateCost(provider: string, model: string, promptTokens: number, completionTokens: number): number {
    // å®šä¹‰ä¸åŒæä¾›å•†å’Œæ¨¡å‹çš„å®šä»·ï¼ˆæ¯1K tokençš„ä»·æ ¼ï¼Œå•ä½ï¼šç¾å…ƒï¼‰
    const pricing: Record<string, Record<string, { input: number; output: number }>> = {
      'openai': {
        'gpt-3.5-turbo': { input: 0.0015, output: 0.002 },
        'gpt-4': { input: 0.03, output: 0.06 },
        'gpt-4o': { input: 0.005, output: 0.015 },
        'gpt-4o-mini': { input: 0.00015, output: 0.0006 }
      },
      'siliconflow': {
        'Qwen/Qwen3-32B': { input: 0.0001, output: 0.0001 },
        'Qwen/Qwen3-8B': { input: 0.00005, output: 0.00005 },
        'deepseek-chat': { input: 0.00014, output: 0.00028 }
      },
      'deepseek': {
        'deepseek-chat': { input: 0.00014, output: 0.00028 },
        'deepseek-coder': { input: 0.00014, output: 0.00028 }
      }
    };

    // è·å–å®šä»·ä¿¡æ¯
    const providerPricing = pricing[provider.toLowerCase()];
    if (!providerPricing) {
      return 0; // æœªçŸ¥æä¾›å•†ï¼Œè¿”å›0æˆæœ¬
    }

    const modelPricing = providerPricing[model];
    if (!modelPricing) {
      return 0; // æœªçŸ¥æ¨¡å‹ï¼Œè¿”å›0æˆæœ¬
    }

    // è®¡ç®—æˆæœ¬
    const inputCost = (promptTokens / 1000) * modelPricing.input;
    const outputCost = (completionTokens / 1000) * modelPricing.output;
    
    return parseFloat((inputCost + outputCost).toFixed(6));
  }
}
